this is my exercise:
ונתולדתשהבו ד"סב
 Homework 2 – Logical Inference
 Introduction
We continue in the world of Harry Potter. This time, Harry heard a rumor that one of the deathly
hallows is hidden in one of the Gringotts bank vaults, and since such a tool can be useful in winning
the war, he intends to break in and find the important artifact – without dying or getting caught in
the way. However, the task will not be so easy, since Gringotts is very secretive about the structure of
the vaults and is also known to use dragons and traps to stop any intruders.
Hermione Granger, a powerful wizard friend of Harry, offered Harry some help in the shape of a spell
cloak cast on him. The spell cloak allows Harry to discover ahead of time where the traps are. When
Harry stands next to a trap, he gets a strong smell of sulfur.
To achieve this most efficiently, you must make use of the algorithms shown in class, specifically
using the logical inference methods.
Environment
The environment is represented as a rectangular grid, with details provided in the “Input” section as
a dictionary. Notice that in this task you will not get the entire map in the initial condition and will
have to discover it while searching for the deathly hallow. Each cell within this grid symbolizes a
different region in the world. Some cells might contain a vault, a dragon, or a trap (or any
combination of these, but never dragon and vault).
The core objective is to navigate strategically to find the deathly hallow without Harry getting killed
or caught.
Each action in this environment occurs in discrete turns, altering the state of the environment and
the current position of Harry.
Note:
• The only thing that changes its location during this game is Harry. The vaults, traps and
dragons do not change their positions.
Actions
You assume control of Harry, which can perform various actions to navigate the world, destroy traps
and avoid dragons:
1. Move: Harry can move up to one tile vertically or horizontally on the grid (he cannot move
diagonally). The action’s syntax is (“move”, (row_idx, col_idx)). For example, if you want to
move Harry to a tile (0,2), the correct syntax for this action is (“move”, (0, 2)).
2. Destroy trap: Harry can destroy a trap if he is in a tile that is directly next to the trap. The
syntax for this action is (“destroy”, (row_idx,col_idx)). For example, if you want Harry to
destroy a trap that is in (0,2), the correct syntax for this action is (“destroy”, (0, 2)).
3. Wait: Harry can choose to wait, which does not change anything about its state or position.
The syntax for this action is (“wait”,).
ונתולדתשהבו ד"סב
 4. Collect: Once Harry reaches a vault, he can try to collect the deathly hallow that lies within.
The syntax for this action is (“collect”,). However, the deathly hallow might be in another
vault – in this case the game continues. If the deathly hallow in indeed in the vault, the
hallow is collected and the game stops.
Notice that each action is a tuple, even if its size is 1.
Each of the above actions is performed in turns or timestamps. After the action is performed, you
are given an observation of the environment. The observations are used to expand your knowledge
base about the environment, which you can (and should) use to guide your next actions.
Note:
• Ensure Harry does not step over the edge of the map.
• Ensure Harry does not step into a tile with a trap or a dragon, both will result in the game
being lost.
Observations
As stated above, after every action you perform you receive an observation about the environment.
Harry can observe the following two things:
1. Vault – If Harry stands one square away from a vault (not diagonally), he can see that indeed
there is a vault there (and exactly where it is). The syntax for this observation is (“vault”,
(row_idx,col_idx)). For example, if Harry moves to a tile (0,2) and there is a vault in (0, 3),
you will get (“vault”, (0, 3)).
2. Dragon – If Harry stands one square away from a dragon (not diagonally), he can see that
indeed there is a dragon there (and exactly where it is). The syntax for this observation is
(“dragon”, (row_idx,col_idx)). For example, if Harry moves to a tile (0,2) and there is a
dragon in (0, 3), you will get (“dragon”, (0, 3)).
3. Sulfur – If Harry stands next to a trap, he can smell sulfur (but does not know where the trap
is). The syntax for this observation is (“sulfur”,).
Notice that each observation is a tuple, even if its size is 1.
After every action you perform, you will receive a list of observations. The list may be empty.
Goal
The overall goal is to collect the deathly hallow without Harry getting caught in a trap or stepping
into a dragon tile. You are required to finish this task in at most 5 + 1.5 * circumference_of_map
turns (regardless of actual time it takes you to make the calculations).
Additional clarification
1. Null actions: Trying to destroy a trap that does not exist is a valid action and will result in no
change in the board. Similarly, trying to collect the deathly hallow from a place that does not
have it (a vault or any other tile) will result in no change in the board.
Input and the task
ונתולדתשהבו ד"סב
 You are required to implement the class “GringottsController”, which has the following two
methods:
1. Init – initialize the controller. The input for this action will be three variables:
a. Map_shape – the dimensions of the map.
b. Harry_loc – the starting location of Harry.
c. Initial_observations – the observations you receive from the starting location, in the
format stated above.
2. Get_next_action – in this method you should implement the policy for choosing the next
action. This method will be repeatedly called from the checker and is the only way you can
progress in the game. The method should only return legal action, otherwise the code will
fail. Every time this method is called you will receive observations from your current
location. The input will be a single variable:
a. Observations – the observations from your current location, in the format stated
above.
Full example of an input for both methods (this example appears in the file ‘inputs.py’ you received):
Evaluating your solution
Having implemented all the methods above, you may launch the checker.py file to check your results
over the inputs. Your code should finish the init method in 60 seconds and the get_next_action
method in 5 seconds every time they are called1. We encourage you to create more input and learn
from them how to improve your code.
Output
You may encounter one of the following outputs for every one of the inputs:
• A bug – self-explanatory.
• Timeout message – your code takes too long to run.
• Illegal action message – self-explanatory.
• A message stating how fast your code has solved the input (in number of turns).
Code handout
Code that you receive has 4 files:
1The code will be checked on an i7 intel processor with 16GB of RAM. To ensure you stand in the time limits
you can also check the time your code takes using the time library. The time given is significantly bigger than
the time necessary to make most of the computations we tried on this exercise.
ונתולדתשהבו ד"סב
 1. ex2.py – the main file that you should modify (has the controller class), implements the
specific problem.
2. check.py – the file that includes some wrappers and inputs and the checker of your
controller, the file that you should run.
3. utils.py – the file that contains some utility functions. You may use the contents of this file
as you see fit.
4. Inputs.py – the file that contains some examples of inputs. If you add inputs, it should be
here.
Note: You may use any package that appears in the standard library, however, the exercise is built in
a way that most packages will be useless. Any other packages are not allowed. Use the python 3.10
version for running the code.
Submission and grading
You are to submit only the file named ex2.py as python file (no zip, rar, etc.). We will run check.py
with our own inputs, and your ex2.py.
The check is fully automated, so it is important to be careful with the names of functions and classes.
The grades will be assigned as follows:
• 85 points – Solving all the non-competitive problems under 60 seconds plus five seconds per
action.
• 25 points – competitive part. Solving extra inputs in the smallest possible number of turns
(not necessarily optimal, just in less turns than others) for as many problems as possible.
This grade will be relative to the other students in the class. The problems which will be
tested might be bigger than in the non-competitive part. You should aim for a small number
of turns even at the expense of longer time for every turn, but should not take more than
the allowed amount of time.
• Notice, you can get more than 100 points in this HW. Scores above 100 will not be rounded
down to 100.
• The submission is due on 15.1, at 23:59
• Submission in pairs/singles only.
• Write your ID numbers in the appropriate field (‘ids’ in ex2.py) as strings. If you submit
alone, leave only one string.

this is checker.py:

import ex2
import time
import inputs

CODES_NEW = {'passage': 0, 'dragon': 1, 'vault': 2, 'trap': 3, 'hollow_vault': 4, 'vault_trap': 5, 'dragon_trap': 6,
             'hollow_trap_vault': 7}
INVERSE_CODES_NEW = dict([(j, i) for i, j in CODES_NEW.items()])
ACTION_TIMEOUT = 5
CONSTRUCTOR_TIMEOUT = 60
DIRECTIONS = [(0, 1), (0, -1), (1, 0), (-1, 0)]
INFINITY = 100000


class Checker:
    def __init__(self):
        pass

    def check_controller(self):
        pass

    def true_state_to_controller_input(self):
        pass

    def is_action_legal(self, action):
        pass

    def change_state_after_action(self, action):
        pass

    def at_goal(self):
        pass


class GringottsChecker(Checker):
    game_map: list
    harry_cur_loc: tuple
    turn_limit: int
    dragon_locs: list
    trap_locs: list
    vault_locs: list
    hollow_loc: tuple
    collected_hollow: bool

    def __init__(self, input):
        super().__init__()
        self.game_map = input['full_map']
        self.harry_cur_loc = input['Harry_start']
        self.dragon_locs = [(x, y) for x in range(len(self.game_map)) for y in range(len(self.game_map[x]))
                            if 'dragon' in INVERSE_CODES_NEW[self.game_map[x][y]]]
        self.trap_locs = [(x, y) for x in range(len(self.game_map)) for y in range(len(self.game_map[x]))
                          if 'trap' in INVERSE_CODES_NEW[self.game_map[x][y]]]
        self.vault_locs = [(x, y) for x in range(len(self.game_map)) for y in range(len(self.game_map[x]))
                           if 'vault' in INVERSE_CODES_NEW[self.game_map[x][y]]]
        self.hollow_loc = [(x, y) for x in range(len(self.game_map)) for y in range(len(self.game_map[x]))
                           if 'hollow' in INVERSE_CODES_NEW[self.game_map[x][y]]][0]  # Should only be one
        m = len(self.game_map)
        n = len(self.game_map[0])
        self.turn_limit = 5 + 3 * (n + m)
        self.collected_hollow = False
        print(f"Maximal amount of turns is {self.turn_limit}!")

    def check_controller(self):
        map_dimensions = (len(self.game_map), len(self.game_map[0]))
        observations = self.create_observations()
        constructor_start = time.time()
        controller = ex2.GringottsController(map_dimensions, self.harry_cur_loc, observations)
        constructor_finish = time.time()
        if constructor_finish - constructor_start > CONSTRUCTOR_TIMEOUT:
            return f"Timeout on constructor! Took {constructor_finish - constructor_start} seconds," \
                   f" should take no more than {CONSTRUCTOR_TIMEOUT}"

        counter = 0
        while not self.at_goal():
            observations = self.create_observations()
            start = time.time()
            action = controller.get_next_action(observations)
            finish = time.time()
            if finish - start > ACTION_TIMEOUT:
                return f"Timeout on action! Took {finish - start} seconds, should take no more than {ACTION_TIMEOUT}"
            if not self.is_action_legal(action):
                return f"Action {action} is illegal! Either because the action is impossible or because Harry dies"
            counter += 1
            print(f"Action {action} took {finish - start} seconds!")
            if counter > self.turn_limit:
                return "Turn limit exceeded!"
            self.change_state_after_action(action)
        return f"Goal achieved in {counter} steps!"

    def create_state(self):
        return self.harry_cur_loc

    def create_observations(self):
        observations = []
        close_locs = self.get_close_locs()
        for loc in close_locs:
            if 'dragon' in INVERSE_CODES_NEW[self.game_map[loc[0]][loc[1]]]:
                observations.append(('dragon', loc))
            if 'vault' in INVERSE_CODES_NEW[self.game_map[loc[0]][loc[1]]]:
                observations.append(('vault', loc))
            if 'trap' in INVERSE_CODES_NEW[self.game_map[loc[0]][loc[1]]]:
                observations.append(tuple(['sulfur']))
        observations = list(set(observations))  # Remove duplicates of traps
        return observations

    def is_action_legal(self, action):
        if len(action) == 0 or len(action) >= 3:
            return False
        if len(action) == 1:
            if action[0] == 'wait':
                return True
            if action[0] == 'collect':
                return True
            else:
                return False
        else:
            close_locs = self.get_close_locs()
            if action[0] == 'destroy':
                if action[1] in close_locs:
                    return True
                else:
                    return False
            elif action[0] == 'move':
                new_loc = action[1]
                if new_loc in close_locs:
                    if new_loc in self.dragon_locs:
                        return False
                    if new_loc in self.trap_locs:
                        return False
                    return True
            return False

    def get_close_locs(self):
        harry_y, harry_x = self.harry_cur_loc
        num_rows = len(self.game_map)
        num_cols = len(self.game_map[0])
        return [(harry_y + direction[0], harry_x + direction[1]) for direction in DIRECTIONS
                if ((0 <= harry_y + direction[0] < num_rows) and
                    (0 <= harry_x + direction[1] < num_cols))]

    def change_state_after_action(self, action):
        if action[0] == "move":
            self.change_state_after_moving(action)
        elif action[0] == "destroy":
            self.change_state_after_destroy(action)
        elif action[0] == "collect":
            self.change_state_after_collect()

    def change_state_after_moving(self, action):
        _, loc = action
        self.harry_cur_loc = loc

    def change_state_after_destroy(self, action):
        _, loc = action
        if loc in self.trap_locs:
            self.trap_locs.remove(loc)
            prev_status = INVERSE_CODES_NEW[self.game_map[loc[0]][loc[1]]]
            if prev_status == 'trap':
                new_status = 'passage'
            elif prev_status == 'vault_trap':
                new_status = 'vault'
            elif prev_status == 'dragon_trap':
                new_status = 'dragon'
            else:
                new_status = 'hollow_vault'
            self.game_map[loc[0]][loc[1]] = CODES_NEW[new_status]

    def change_state_after_collect(self):
        if self.harry_cur_loc == self.hollow_loc:
            self.collected_hollow = True

    def at_goal(self):
        return self.collected_hollow


if __name__ == '__main__':
    print(ex2.ids)
    for number, input in enumerate(inputs.easy_inputs):
        my_checker = GringottsChecker(input)
        print(f"Output on input number {number + 1}: {my_checker.check_controller()}")

this is utils.py:
"""Provides some utilities widely used by other modules"""

import bisect
import collections
import collections.abc
import operator
import os.path
import random
import math
import functools
from itertools import chain, combinations


# ______________________________________________________________________________
# Functions on Sequences and Iterables


def sequence(iterable):
    """Coerce iterable to sequence, if it is not already one."""
    return (iterable if isinstance(iterable, collections.abc.Sequence)
            else tuple(iterable))

def remove_all(item, seq):
    """Return a copy of seq (or string) with all occurrences of item removed."""
    if isinstance(seq, str):
        return seq.replace(item, '')
    elif isinstance(seq, set):
        rest = seq.copy()
        rest.remove(item)
        return rest
    else:
        return [x for x in seq if x != item]


def unique(seq):  # TODO: replace with set
    """Remove duplicate elements from seq. Assumes hashable elements."""
    return list(set(seq))


def count(seq):
    """Count the number of items in sequence that are interpreted as true."""
    return sum(bool(x) for x in seq)


def product(numbers):
    """Return the product of the numbers, e.g. product([2, 3, 10]) == 60"""
    result = 1
    for x in numbers:
        result *= x
    return result


def first(iterable, default=None):
    """Return the first element of an iterable or the next element of a generator; or default."""
    try:
        return iterable[0]
    except IndexError:
        return default
    except TypeError:
        return next(iterable, default)


def is_in(elt, seq):
    """Similar to (elt in seq), but compares with 'is', not '=='."""
    return any(x is elt for x in seq)


def mode(data):
    """Return the most common data item. If there are ties, return any one of them."""
    [(item, count)] = collections.Counter(data).most_common(1)
    return item


def powerset(iterable):
    """powerset([1,2,3]) --> (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"""
    s = list(iterable)
    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))[1:]


# ______________________________________________________________________________
# argmin and argmax


identity = lambda x: x

argmin = min
argmax = max


def argmin_random_tie(seq, key=identity):
    """Return a minimum element of seq; break ties at random."""
    return argmin(shuffled(seq), key=key)


def argmax_random_tie(seq, key=identity):
    """Return an element with highest fn(seq[i]) score; break ties at random."""
    return argmax(shuffled(seq), key=key)


def shuffled(iterable):
    """Randomly shuffle a copy of iterable."""
    items = list(iterable)
    random.shuffle(items)
    return items


# ______________________________________________________________________________
# Statistical and mathematical functions


def histogram(values, mode=0, bin_function=None):
    """Return a list of (value, count) pairs, summarizing the input values.
    Sorted by increasing value, or if mode=1, by decreasing count.
    If bin_function is given, map it over values first."""
    if bin_function:
        values = map(bin_function, values)

    bins = {}
    for val in values:
        bins[val] = bins.get(val, 0) + 1

    if mode:
        return sorted(list(bins.items()), key=lambda x: (x[1], x[0]),
                      reverse=True)
    else:
        return sorted(bins.items())


def dotproduct(X, Y):
    """Return the sum of the element-wise product of vectors X and Y."""
    return sum(x * y for x, y in zip(X, Y))


def element_wise_product(X, Y):
    """Return vector as an element-wise product of vectors X and Y"""
    assert len(X) == len(Y)
    return [x * y for x, y in zip(X, Y)]


def matrix_multiplication(X_M, *Y_M):
    """Return a matrix as a matrix-multiplication of X_M and arbitary number of matrices *Y_M"""

    def _mat_mult(X_M, Y_M):
        """Return a matrix as a matrix-multiplication of two matrices X_M and Y_M
        >>> matrix_multiplication([[1, 2, 3],
                                   [2, 3, 4]],
                                   [[3, 4],
                                    [1, 2],
                                    [1, 0]])
        [[8, 8],[13, 14]]
        """
        assert len(X_M[0]) == len(Y_M)

        result = [[0 for i in range(len(Y_M[0]))] for j in range(len(X_M))]
        for i in range(len(X_M)):
            for j in range(len(Y_M[0])):
                for k in range(len(Y_M)):
                    result[i][j] += X_M[i][k] * Y_M[k][j]
        return result

    result = X_M
    for Y in Y_M:
        result = _mat_mult(result, Y)

    return result


def vector_to_diagonal(v):
    """Converts a vector to a diagonal matrix with vector elements
    as the diagonal elements of the matrix"""
    diag_matrix = [[0 for i in range(len(v))] for j in range(len(v))]
    for i in range(len(v)):
        diag_matrix[i][i] = v[i]

    return diag_matrix


def vector_add(a, b):
    """Component-wise addition of two vectors."""
    return tuple(map(operator.add, a, b))


def scalar_vector_product(X, Y):
    """Return vector as a product of a scalar and a vector"""
    return [X * y for y in Y]


def scalar_matrix_product(X, Y):
    """Return matrix as a product of a scalar and a matrix"""
    return [scalar_vector_product(X, y) for y in Y]


def inverse_matrix(X):
    """Inverse a given square matrix of size 2x2"""
    assert len(X) == 2
    assert len(X[0]) == 2
    det = X[0][0] * X[1][1] - X[0][1] * X[1][0]
    assert det != 0
    inv_mat = scalar_matrix_product(1.0/det, [[X[1][1], -X[0][1]], [-X[1][0], X[0][0]]])

    return inv_mat


def probability(p):
    """Return true with probability p."""
    return p > random.uniform(0.0, 1.0)


def weighted_sample_with_replacement(n, seq, weights):
    """Pick n samples from seq at random, with replacement, with the
    probability of each element in proportion to its corresponding
    weight."""
    sample = weighted_sampler(seq, weights)

    return [sample() for _ in range(n)]


def weighted_sampler(seq, weights):
    """Return a random-sample function that picks from seq weighted by weights."""
    totals = []
    for w in weights:
        totals.append(w + totals[-1] if totals else w)

    return lambda: seq[bisect.bisect(totals, random.uniform(0, totals[-1]))]


def rounder(numbers, d=4):
    """Round a single number, or sequence of numbers, to d decimal places."""
    if isinstance(numbers, (int, float)):
        return round(numbers, d)
    else:
        constructor = type(numbers)     # Can be list, set, tuple, etc.
        return constructor(rounder(n, d) for n in numbers)


def num_or_str(x):
    """The argument is a string; convert to a number if
       possible, or strip it."""
    try:
        return int(x)
    except ValueError:
        try:
            return float(x)
        except ValueError:
            return str(x).strip()


def normalize(dist):
    """Multiply each number by a constant such that the sum is 1.0"""
    if isinstance(dist, dict):
        total = sum(dist.values())
        for key in dist:
            dist[key] = dist[key] / total
            assert 0 <= dist[key] <= 1, "Probabilities must be between 0 and 1."
        return dist
    total = sum(dist)
    return [(n / total) for n in dist]


def norm(X, n=2):
    """Return the n-norm of vector X"""
    return sum([x**n for x in X])**(1/n)


def clip(x, lowest, highest):
    """Return x clipped to the range [lowest..highest]."""
    return max(lowest, min(x, highest))


def sigmoid_derivative(value):
    return value * (1 - value)


def sigmoid(x):
    """Return activation value of x with sigmoid function"""
    return 1/(1 + math.exp(-x))


def step(x):
    """Return activation value of x with sign function"""
    return 1 if x >= 0 else 0


def gaussian(mean, st_dev, x):
    """Given the mean and standard deviation of a distribution, it returns the probability of x."""
    return 1/(math.sqrt(2*math.pi)*st_dev)*math.e**(-0.5*(float(x-mean)/st_dev)**2)


try:  # math.isclose was added in Python 3.5; but we might be in 3.4
    from math import isclose
except ImportError:
    def isclose(a, b, rel_tol=1e-09, abs_tol=0.0):
        """Return true if numbers a and b are close to each other."""
        return abs(a - b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)


def weighted_choice(choices):
    """A weighted version of random.choice"""
    # NOTE: Shoule be replaced by random.choices if we port to Python 3.6

    total = sum(w for _, w in choices)
    r = random.uniform(0, total)
    upto = 0
    for c, w in choices:
        if upto + w >= r:
            return c, w
        upto += w


# ______________________________________________________________________________
# Grid Functions


orientations = EAST, NORTH, WEST, SOUTH = [(1, 0), (0, 1), (-1, 0), (0, -1)]
turns = LEFT, RIGHT = (+1, -1)


def turn_heading(heading, inc, headings=orientations):
    return headings[(headings.index(heading) + inc) % len(headings)]


def turn_right(heading):
    return turn_heading(heading, RIGHT)


def turn_left(heading):
    return turn_heading(heading, LEFT)


def distance(a, b):
    """The distance between two (x, y) points."""
    xA, yA = a
    xB, yB = b
    return math.hypot((xA - xB), (yA - yB))


def distance_squared(a, b):
    """The square of the distance between two (x, y) points."""
    xA, yA = a
    xB, yB = b
    return (xA - xB)**2 + (yA - yB)**2


def vector_clip(vector, lowest, highest):
    """Return vector, except if any element is less than the corresponding
    value of lowest or more than the corresponding value of highest, clip to
    those values."""
    return type(vector)(map(clip, vector, lowest, highest))


# ______________________________________________________________________________
# Misc Functions


def memoize(fn, slot=None, maxsize=32):
    """Memoize fn: make it remember the computed value for any argument list.
    If slot is specified, store result in that slot of first argument.
    If slot is false, use lru_cache for caching the values."""
    if slot:
        def memoized_fn(obj, *args):
            if hasattr(obj, slot):
                return getattr(obj, slot)
            else:
                val = fn(obj, *args)
                setattr(obj, slot, val)
                return val
    else:
        @functools.lru_cache(maxsize=maxsize)
        def memoized_fn(*args):
            return fn(*args)

    return memoized_fn


def name(obj):
    """Try to find some reasonable name for the object."""
    return (getattr(obj, 'name', 0) or getattr(obj, '__name__', 0) or
            getattr(getattr(obj, '__class__', 0), '__name__', 0) or
            str(obj))


def isnumber(x):
    """Is x a number?"""
    return hasattr(x, '__int__')


def issequence(x):
    """Is x a sequence?"""
    return isinstance(x, collections.abc.Sequence)


def print_table(table, header=None, sep='   ', numfmt='{}'):
    """Print a list of lists as a table, so that columns line up nicely.
    header, if specified, will be printed as the first row.
    numfmt is the format for all numbers; you might want e.g. '{:.2f}'.
    (If you want different formats in different columns,
    don't use print_table.) sep is the separator between columns."""
    justs = ['rjust' if isnumber(x) else 'ljust' for x in table[0]]

    if header:
        table.insert(0, header)

    table = [[numfmt.format(x) if isnumber(x) else x for x in row]
             for row in table]

    sizes = list(
            map(lambda seq: max(map(len, seq)),
                list(zip(*[map(str, row) for row in table]))))

    for row in table:
        print(sep.join(getattr(
            str(x), j)(size) for (j, size, x) in zip(justs, sizes, row)))


def open_data(name, mode='r'):
    aima_root = os.path.dirname(__file__)
    aima_file = os.path.join(aima_root, *['aima-data', name])

    return open(aima_file)


# ______________________________________________________________________________
# Expressions

# See https://docs.python.org/3/reference/expressions.html#operator-precedence
# See https://docs.python.org/3/reference/datamodel.html#special-method-names

class Expr(object):
    """A mathematical expression with an operator and 0 or more arguments.
    op is a str like '+' or 'sin'; args are Expressions.
    Expr('x') or Symbol('x') creates a symbol (a nullary Expr).
    Expr('-', x) creates a unary; Expr('+', x, 1) creates a binary."""

    def __init__(self, op, *args):
        self.op = str(op)
        self.args = args

    # Operator overloads
    def __neg__(self):
        return Expr('-', self)

    def __pos__(self):
        return Expr('+', self)

    def __invert__(self):
        return Expr('~', self)

    def __add__(self, rhs):
        return Expr('+', self, rhs)

    def __sub__(self, rhs):
        return Expr('-', self, rhs)

    def __mul__(self, rhs):
        return Expr('*', self, rhs)

    def __pow__(self, rhs):
        return Expr('**', self, rhs)

    def __mod__(self, rhs):
        return Expr('%', self, rhs)

    def __and__(self, rhs):
        return Expr('&', self, rhs)

    def __xor__(self, rhs):
        return Expr('^', self, rhs)

    def __rshift__(self, rhs):
        return Expr('>>', self, rhs)

    def __lshift__(self, rhs):
        return Expr('<<', self, rhs)

    def __truediv__(self, rhs):
        return Expr('/', self, rhs)

    def __floordiv__(self, rhs):
        return Expr('//', self, rhs)

    def __matmul__(self, rhs):
        return Expr('@', self, rhs)

    def __or__(self, rhs):
        """Allow both P | Q, and P |'==>'| Q."""
        if isinstance(rhs, Expression):
            return Expr('|', self, rhs)
        else:
            return PartialExpr(rhs, self)

    # Reverse operator overloads
    def __radd__(self, lhs):
        return Expr('+', lhs, self)

    def __rsub__(self, lhs):
        return Expr('-', lhs, self)

    def __rmul__(self, lhs):
        return Expr('*', lhs, self)

    def __rdiv__(self, lhs):
        return Expr('/', lhs, self)

    def __rpow__(self, lhs):
        return Expr('**', lhs, self)

    def __rmod__(self, lhs):
        return Expr('%', lhs, self)

    def __rand__(self, lhs):
        return Expr('&', lhs, self)

    def __rxor__(self, lhs):
        return Expr('^', lhs, self)

    def __ror__(self, lhs):
        return Expr('|', lhs, self)

    def __rrshift__(self, lhs):
        return Expr('>>', lhs, self)

    def __rlshift__(self, lhs):
        return Expr('<<', lhs, self)

    def __rtruediv__(self, lhs):
        return Expr('/', lhs, self)

    def __rfloordiv__(self, lhs):
        return Expr('//', lhs, self)

    def __rmatmul__(self, lhs):
        return Expr('@', lhs, self)

    def __call__(self, *args):
        "Call: if 'f' is a Symbol, then f(0) == Expr('f', 0)."
        if self.args:
            raise ValueError('can only do a call for a Symbol, not an Expr')
        else:
            return Expr(self.op, *args)

    # Equality and repr
    def __eq__(self, other):
        "'x == y' evaluates to True or False; does not build an Expr."
        return (isinstance(other, Expr)
                and self.op == other.op
                and self.args == other.args)

    def __hash__(self): return hash(self.op) ^ hash(self.args)

    def __repr__(self):
        op = self.op
        args = [str(arg) for arg in self.args]
        if op.isidentifier():       # f(x) or f(x, y)
            return '{}({})'.format(op, ', '.join(args)) if args else op
        elif len(args) == 1:        # -x or -(x + 1)
            return op + args[0]
        else:                       # (x - y)
            opp = (' ' + op + ' ')
            return '(' + opp.join(args) + ')'

# An 'Expression' is either an Expr or a Number.
# Symbol is not an explicit type; it is any Expr with 0 args.


Number = (int, float, complex)
Expression = (Expr, Number)


def Symbol(name):
    """A Symbol is just an Expr with no args."""
    return Expr(name)


def symbols(names):
    """Return a tuple of Symbols; names is a comma/whitespace delimited str."""
    return tuple(Symbol(name) for name in names.replace(',', ' ').split())


def subexpressions(x):
    """Yield the subexpressions of an Expression (including x itself)."""
    yield x
    if isinstance(x, Expr):
        for arg in x.args:
            yield from subexpressions(arg)


def arity(expression):
    """The number of sub-expressions in this expression."""
    if isinstance(expression, Expr):
        return len(expression.args)
    else:  # expression is a number
        return 0

# For operators that are not defined in Python, we allow new InfixOps:


class PartialExpr:
    """Given 'P |'==>'| Q, first form PartialExpr('==>', P), then combine with Q."""
    def __init__(self, op, lhs):
        self.op, self.lhs = op, lhs

    def __or__(self, rhs):
        return Expr(self.op, self.lhs, rhs)

    def __repr__(self):
        return "PartialExpr('{}', {})".format(self.op, self.lhs)


def expr(x):
    """Shortcut to create an Expression. x is a str in which:
    - identifiers are automatically defined as Symbols.
    - ==> is treated as an infix |'==>'|, as are <== and <=>.
    If x is already an Expression, it is returned unchanged. Example:
    >>> expr('P & Q ==> Q')
    ((P & Q) ==> Q)
    """
    if isinstance(x, str):
        return eval(expr_handle_infix_ops(x), defaultkeydict(Symbol))
    else:
        return x


infix_ops = '==> <== <=>'.split()


def expr_handle_infix_ops(x):
    """Given a str, return a new str with ==> replaced by |'==>'|, etc.
    >>> expr_handle_infix_ops('P ==> Q')
    "P |'==>'| Q"
    """
    for op in infix_ops:
        x = x.replace(op, '|' + repr(op) + '|')
    return x


class defaultkeydict(collections.defaultdict):
    """Like defaultdict, but the default_factory is a function of the key.
    >>> d = defaultkeydict(len); d['four']
    4
    """
    def __missing__(self, key):
        self[key] = result = self.default_factory(key)
        return result


class hashabledict(dict):
    """Allows hashing by representing a dictionary as tuple of key:value pairs
       May cause problems as the hash value may change during runtime
    """
    def __tuplify__(self):
        return tuple(sorted(self.items()))

    def __hash__(self):
        return hash(self.__tuplify__())

    def __lt__(self, odict):
        assert isinstance(odict, hashabledict)
        return self.__tuplify__() < odict.__tuplify__()

    def __gt__(self, odict):
        assert isinstance(odict, hashabledict)
        return self.__tuplify__() > odict.__tuplify__()

    def __le__(self, odict):
        assert isinstance(odict, hashabledict)
        return self.__tuplify__() <= odict.__tuplify__()

    def __ge__(self, odict):
        assert isinstance(odict, hashabledict)
        return self.__tuplify__() >= odict.__tuplify__()


# ______________________________________________________________________________
# Queues: Stack, FIFOQueue, PriorityQueue

# TODO: queue.PriorityQueue
# TODO: Priority queues may not belong here -- see treatment in search.py


class Queue:

    """Queue is an abstract class/interface. There are three types:
        Stack(): A Last In First Out Queue.
        FIFOQueue(): A First In First Out Queue.
        PriorityQueue(order, f): Queue in sorted order (default min-first).
    Each type supports the following methods and functions:
        q.append(item)  -- add an item to the queue
        q.extend(items) -- equivalent to: for item in items: q.append(item)
        q.pop()         -- return the top item from the queue
        len(q)          -- number of items in q (also q.__len())
        item in q       -- does q contain item?
    Note that isinstance(Stack(), Queue) is false, because we implement stacks
    as lists.  If Python ever gets interfaces, Queue will be an interface."""

    def __init__(self):
        raise NotImplementedError

    def extend(self, items):
        for item in items:
            self.append(item)


def Stack():
    """Return an empty list, suitable as a Last-In-First-Out Queue."""
    return []


class FIFOQueue(Queue):

    """A First-In-First-Out Queue."""

    def __init__(self, maxlen=None, items=[]):
        self.queue = collections.deque(items, maxlen)

    def append(self, item):
        if not self.queue.maxlen or len(self.queue) < self.queue.maxlen:
            self.queue.append(item)
        else:
            raise Exception('FIFOQueue is full')

    def extend(self, items):
        if not self.queue.maxlen or len(self.queue) + len(items) <= self.queue.maxlen:
            self.queue.extend(items)
        else:
            raise Exception('FIFOQueue max length exceeded')

    def pop(self):
        if len(self.queue) > 0:
            return self.queue.popleft()
        else:
            raise Exception('FIFOQueue is empty')

    def __len__(self):
        return len(self.queue)

    def __contains__(self, item):
        return item in self.queue


class PriorityQueue(Queue):

    """A queue in which the minimum (or maximum) element (as determined by f and
    order) is returned first. If order is min, the item with minimum f(x) is
    returned first; if order is max, then it is the item with maximum f(x).
    Also supports dict-like lookup."""

    def __init__(self, order=min, f=lambda x: x):
        self.A = []
        self.order = order
        self.f = f

    def append(self, item):
        bisect.insort(self.A, (self.f(item), item))

    def __len__(self):
        return len(self.A)

    def pop(self):
        if self.order == min:
            return self.A.pop(0)[1]
        else:
            return self.A.pop()[1]

    def __contains__(self, item):
        return any(item == pair[1] for pair in self.A)

    def __getitem__(self, key):
        for _, item in self.A:
            if item == key:
                return item

    def __delitem__(self, key):
        for i, (value, item) in enumerate(self.A):
            if item == key:
                self.A.pop(i)


# ______________________________________________________________________________
# Useful Shorthands


class Bool(int):
    """Just like `bool`, except values display as 'T' and 'F' instead of 'True' and 'False'"""
    __str__ = __repr__ = lambda self: 'T' if self else 'F'


T = Bool(True)
F = Bool(False)



"""
Representations and Inference for Logic (Chapters 7-9, 12)

Covers both Propositional and First-Order Logic. First we have four
important data types:

    KB            Abstract class holds a knowledge base of logical expressions
    KB_Agent      Abstract class subclasses agents.Agent
    Expr          A logical expression, imported from utils.py
    substitution  Implemented as a dictionary of var:value pairs, {x:1, y:x}

Be careful: some functions take an Expr as argument, and some take a KB.

Logical expressions can be created with Expr or expr, imported from utils, TODO
or with expr, which adds the capability to write a string that uses
the connectives ==>, <==, <=>, or <=/=>. But be careful: these have the
operator precedence of commas; you may need to add parens to make precedence work.

Then we implement various functions for doing logical inference:

    pl_true          Evaluate a propositional logical sentence in a model
    tt_entails       Say if a statement is entailed by a KB
    pl_resolution    Do resolution on propositional sentences
    dpll_satisfiable See if a propositional sentence is satisfiable


And a few other functions:

    to_cnf           Convert to conjunctive normal form
    unify            Do unification of two FOL sentences
    diff, simp       Symbolic differentiation and simplification
"""

import heapq
import itertools
import random
from collections import defaultdict, Counter

import networkx as nx

class KB:
    """A knowledge base to which you can tell and ask sentences.
    To create a KB, first subclass this class and implement
    tell, ask_generator, and retract. Why ask_generator instead of ask?
    The book is a bit vague on what ask means --
    For a Propositional Logic KB, ask(P & Q) returns True or False, but for an
    FOL KB, something like ask(Brother(x, y)) might return many substitutions
    such as {x: Cain, y: Abel}, {x: Abel, y: Cain}, {x: George, y: Jeb}, etc.
    So ask_generator generates these one at a time, and ask either returns the
    first one or returns False."""

    def __init__(self, sentence=None):
        raise NotImplementedError

    def tell(self, sentence):
        """Add the sentence to the KB."""
        raise NotImplementedError

    def ask(self, query):
        """Return a substitution that makes the query true, or, failing that, return False."""
        return first(self.ask_generator(query), default=False)

    def ask_generator(self, query):
        """Yield all the substitutions that make query true."""
        raise NotImplementedError

    def retract(self, sentence):
        """Remove sentence from the KB."""
        raise NotImplementedError


class PropKB(KB):
    """A KB for propositional logic. Inefficient, with no indexing."""

    def __init__(self, sentence=None):
        self.clauses = []
        if sentence:
            self.tell(sentence)

    def tell(self, sentence):
        """Add the sentence's clauses to the KB."""
        self.clauses.extend(conjuncts(to_cnf(sentence)))

    def ask_generator(self, query):
        """Yield the empty substitution {} if KB entails query; else no results."""
        if tt_entails(Expr('&', *self.clauses), query):
            yield {}

    def ask_if_true(self, query):
        """Return True if the KB entails query, else return False."""
        for _ in self.ask_generator(query):
            return True
        return False

    def retract(self, sentence):
        """Remove the sentence's clauses from the KB."""
        for c in conjuncts(to_cnf(sentence)):
            if c in self.clauses:
                self.clauses.remove(c)


# ______________________________________________________________________________



def tt_entails(kb, alpha):
    """
    [Figure 7.10]
    Does kb entail the sentence alpha? Use truth tables. For propositional
    kb's and sentences. Note that the 'kb' should be an Expr which is a
    conjunction of clauses.
    >>> tt_entails(expr('P & Q'), expr('Q'))
    True
    """
    assert not variables(alpha)
    symbols = list(prop_symbols(kb & alpha))
    return tt_check_all(kb, alpha, symbols, {})

def is_variable(x):
    """A variable is an Expr with no args and a lowercase symbol as the op."""
    return isinstance(x, Expr) and not x.args and x.op[0].islower()



def variables(s):
    """Return a set of the variables in expression s.
    >>> variables(expr('F(x, x) & G(x, y) & H(y, z) & R(A, z, 2)')) == {x, y, z}
    True
    """
    return {x for x in subexpressions(s) if is_variable(x)}

def tt_check_all(kb, alpha, symbols, model):
    """Auxiliary routine to implement tt_entails."""
    if not symbols:
        if pl_true(kb, model):
            result = pl_true(alpha, model)
            assert result in (True, False)
            return result
        else:
            return True
    else:
        P, rest = symbols[0], symbols[1:]
        return (tt_check_all(kb, alpha, rest, extend(model, P, True)) and
                tt_check_all(kb, alpha, rest, extend(model, P, False)))


def extend(s, var, val):
    """Copy dict s and extend it by setting var to val; return copy."""
    return {**s, var: val}


def prop_symbols(x):
    """Return the set of all propositional symbols in x."""
    if not isinstance(x, Expr):
        return set()
    elif is_prop_symbol(x.op):
        return {x}
    else:
        return {symbol for arg in x.args for symbol in prop_symbols(arg)}


def constant_symbols(x):
    """Return the set of all constant symbols in x."""
    if not isinstance(x, Expr):
        return set()
    elif is_prop_symbol(x.op) and not x.args:
        return {x}
    else:
        return {symbol for arg in x.args for symbol in constant_symbols(arg)}


def predicate_symbols(x):
    """Return a set of (symbol_name, arity) in x.
    All symbols (even functional) with arity > 0 are considered."""
    if not isinstance(x, Expr) or not x.args:
        return set()
    pred_set = {(x.op, len(x.args))} if is_prop_symbol(x.op) else set()
    pred_set.update({symbol for arg in x.args for symbol in predicate_symbols(arg)})
    return pred_set


def tt_true(s):
    """Is a propositional sentence a tautology?
    >>> tt_true('P | ~P')
    True
    """
    s = expr(s)
    return tt_entails(True, s)


def pl_true(exp, model={}):
    """Return True if the propositional logic expression is true in the model,
    and False if it is false. If the model does not specify the value for
    every proposition, this may return None to indicate 'not obvious';
    this may happen even when the expression is tautological.
    >>> pl_true(P, {}) is None
    True
    """
    if exp in (True, False):
        return exp
    op, args = exp.op, exp.args
    if is_prop_symbol(op):
        return model.get(exp)
    elif op == '~':
        p = pl_true(args[0], model)
        if p is None:
            return None
        else:
            return not p
    elif op == '|':
        result = False
        for arg in args:
            p = pl_true(arg, model)
            if p is True:
                return True
            if p is None:
                result = None
        return result
    elif op == '&':
        result = True
        for arg in args:
            p = pl_true(arg, model)
            if p is False:
                return False
            if p is None:
                result = None
        return result
    p, q = args
    if op == '==>':
        return pl_true(~p | q, model)
    elif op == '<==':
        return pl_true(p | ~q, model)
    pt = pl_true(p, model)
    if pt is None:
        return None
    qt = pl_true(q, model)
    if qt is None:
        return None
    if op == '<=>':
        return pt == qt
    elif op == '^':  # xor or 'not equivalent'
        return pt != qt
    else:
        raise ValueError('Illegal operator in logic expression' + str(exp))


# ______________________________________________________________________________

# Convert to Conjunctive Normal Form (CNF)


def to_cnf(s):
    """
    [Page 253]
    Convert a propositional logical sentence to conjunctive normal form.
    That is, to the form ((A | ~B | ...) & (B | C | ...) & ...)
    >>> to_cnf('~(B | C)')
    (~B & ~C)
    """
    s = expr(s)
    if isinstance(s, str):
        s = expr(s)
    s = eliminate_implications(s)  # Steps 1, 2 from p. 253
    s = move_not_inwards(s)  # Step 3
    return distribute_and_over_or(s)  # Step 4



def is_symbol(s):
    """A string s is a symbol if it starts with an alphabetic char.
    >>> is_symbol('R2D2')
    True
    """
    return isinstance(s, str) and s[:1].isalpha()


def is_prop_symbol(s):
    """A proposition logic symbol is an initial-uppercase string.
    >>> is_prop_symbol('exe')
    False
    """
    return is_symbol(s) and s[0].isupper()

def eliminate_implications(s):
    """Change implications into equivalent form with only &, |, and ~ as logical operators."""
    s = expr(s)
    if not s.args or is_symbol(s.op):
        return s  # Atoms are unchanged.
    args = list(map(eliminate_implications, s.args))
    a, b = args[0], args[-1]
    if s.op == '==>':
        return b | ~a
    elif s.op == '<==':
        return a | ~b
    elif s.op == '<=>':
        return (a | ~b) & (b | ~a)
    elif s.op == '^':
        assert len(args) == 2  # TODO: relax this restriction
        return (a & ~b) | (~a & b)
    else:
        assert s.op in ('&', '|', '~')
        return Expr(s.op, *args)


def move_not_inwards(s):
    """Rewrite sentence s by moving negation sign inward.
    >>> move_not_inwards(~(A | B))
    (~A & ~B)
    """
    s = expr(s)
    if s.op == '~':
        def NOT(b):
            return move_not_inwards(~b)

        a = s.args[0]
        if a.op == '~':
            return move_not_inwards(a.args[0])  # ~~A ==> A
        if a.op == '&':
            return associate('|', list(map(NOT, a.args)))
        if a.op == '|':
            return associate('&', list(map(NOT, a.args)))
        return s
    elif is_symbol(s.op) or not s.args:
        return s
    else:
        return Expr(s.op, *list(map(move_not_inwards, s.args)))


def distribute_and_over_or(s):
    """Given a sentence s consisting of conjunctions and disjunctions
    of literals, return an equivalent sentence in CNF.
    >>> distribute_and_over_or((A & B) | C)
    ((A | C) & (B | C))
    """
    s = expr(s)
    if s.op == '|':
        s = associate('|', s.args)
        if s.op != '|':
            return distribute_and_over_or(s)
        if len(s.args) == 0:
            return False
        if len(s.args) == 1:
            return distribute_and_over_or(s.args[0])
        conj = first(arg for arg in s.args if arg.op == '&')
        if not conj:
            return s
        others = [a for a in s.args if a is not conj]
        rest = associate('|', others)
        return associate('&', [distribute_and_over_or(c | rest)
                               for c in conj.args])
    elif s.op == '&':
        return associate('&', list(map(distribute_and_over_or, s.args)))
    else:
        return s


def associate(op, args):
    """Given an associative op, return an expression with the same
    meaning as Expr(op, *args), but flattened -- that is, with nested
    instances of the same op promoted to the top level.
    >>> associate('&', [(A&B),(B|C),(B&C)])
    (A & B & (B | C) & B & C)
    >>> associate('|', [A|(B|(C|(A&B)))])
    (A | B | C | (A & B))
    """
    args = dissociate(op, args)
    if len(args) == 0:
        return _op_identity[op]
    elif len(args) == 1:
        return args[0]
    else:
        return Expr(op, *args)


_op_identity = {'&': True, '|': False, '+': 0, '*': 1}


def dissociate(op, args):
    """Given an associative op, return a flattened list result such
    that Expr(op, *result) means the same as Expr(op, *args).
    >>> dissociate('&', [A & B])
    [A, B]
    """
    result = []

    def collect(subargs):
        for arg in subargs:
            if arg.op == op:
                collect(arg.args)
            else:
                result.append(arg)

    collect(args)
    return result


def conjuncts(s):
    """Return a list of the conjuncts in the sentence s.
    >>> conjuncts(A & B)
    [A, B]
    >>> conjuncts(A | B)
    [(A | B)]
    """
    return dissociate('&', [s])


def disjuncts(s):
    """Return a list of the disjuncts in the sentence s.
    >>> disjuncts(A | B)
    [A, B]
    >>> disjuncts(A & B)
    [(A & B)]
    """
    return dissociate('|', [s])


# ______________________________________________________________________________


def pl_resolution(kb, alpha):
    """
    [Figure 7.12]
    Propositional-logic resolution: say if alpha follows from KB.
    >>> pl_resolution(horn_clauses_KB, A)
    True
    """
    clauses = kb.clauses + conjuncts(to_cnf(~alpha))
    new = set()
    while True:
        n = len(clauses)
        pairs = [(clauses[i], clauses[j])
                 for i in range(n) for j in range(i + 1, n)]
        for (ci, cj) in pairs:
            resolvents = pl_resolve(ci, cj)
            if False in resolvents:
                return True
            new = new.union(set(resolvents))
        if new.issubset(set(clauses)):
            return False
        for c in new:
            if c not in clauses:
                clauses.append(c)


def pl_resolve(ci, cj):
    """Return all clauses that can be obtained by resolving clauses ci and cj."""
    clauses = []
    for di in disjuncts(ci):
        for dj in disjuncts(cj):
            if di == ~dj or ~di == dj:
                clauses.append(associate('|', unique(remove_all(di, disjuncts(ci)) + remove_all(dj, disjuncts(cj)))))
    return clauses


# ______________________________________________________________________________

def is_definite_clause(s):
    """Returns True for exprs s of the form A & B & ... & C ==> D,
    where all literals are positive. In clause form, this is
    ~A | ~B | ... | ~C | D, where exactly one clause is positive.
    >>> is_definite_clause(expr('Farmer(Mac)'))
    True
    """
    if is_symbol(s.op):
        return True
    elif s.op == '==>':
        antecedent, consequent = s.args
        return is_symbol(consequent.op) and all(is_symbol(arg.op) for arg in conjuncts(antecedent))
    else:
        return False

class PropDefiniteKB(PropKB):
    """A KB of propositional definite clauses."""

    def tell(self, sentence):
        """Add a definite clause to this KB."""
        assert is_definite_clause(sentence), "Must be definite clause"
        self.clauses.append(sentence)

    def ask_generator(self, query):
        """Yield the empty substitution if KB implies query; else nothing."""
        if pl_fc_entails(self.clauses, query):
            yield {}

    def retract(self, sentence):
        self.clauses.remove(sentence)

    def clauses_with_premise(self, p):
        """Return a list of the clauses in KB that have p in their premise.
        This could be cached away for O(1) speed, but we'll recompute it."""
        return [c for c in self.clauses if c.op == '==>' and p in conjuncts(c.args[0])]


def pl_fc_entails(kb, q):
    """
    [Figure 7.15]
    Use forward chaining to see if a PropDefiniteKB entails symbol q.
    >>> pl_fc_entails(horn_clauses_KB, expr('Q'))
    True
    """
    count = {c: len(conjuncts(c.args[0])) for c in kb.clauses if c.op == '==>'}
    inferred = defaultdict(bool)
    agenda = [s for s in kb.clauses if is_prop_symbol(s.op)]
    while agenda:
        p = agenda.pop()
        if p == q:
            return True
        if not inferred[p]:
            inferred[p] = True
            for c in kb.clauses_with_premise(p):
                count[c] -= 1
                if count[c] == 0:
                    agenda.append(c.args[1])
    return False


"""
[Figure 7.13]
Simple inference in a wumpus world example
"""
wumpus_world_inference = expr('(B11 <=> (P12 | P21))  &  ~B11')

"""
[Figure 7.16]
Propositional Logic Forward Chaining example
"""
horn_clauses_KB = PropDefiniteKB()
for clause in ['P ==> Q',
               '(L & M) ==> P',
               '(B & L) ==> M',
               '(A & P) ==> L',
               '(A & B) ==> L',
               'A', 'B']:
    horn_clauses_KB.tell(expr(clause))

"""
Definite clauses KB example
"""
definite_clauses_KB = PropDefiniteKB()
for clause in ['(B & F) ==> E',
               '(A & E & F) ==> G',
               '(B & C) ==> F',
               '(A & B) ==> D',
               '(E & F) ==> H',
               '(H & I) ==>J',
               'A', 'B', 'C']:
    definite_clauses_KB.tell(expr(clause))


# ______________________________________________________________________________
# Heuristics for SAT Solvers


def no_branching_heuristic(symbols, clauses):
    return first(symbols), True


def min_clauses(clauses):
    min_len = min(map(lambda c: len(c.args), clauses), default=2)
    return filter(lambda c: len(c.args) == (min_len if min_len > 1 else 2), clauses)


def moms(symbols, clauses):
    """
    MOMS (Maximum Occurrence in clauses of Minimum Size) heuristic
    Returns the literal with the most occurrences in all clauses of minimum size
    """
    scores = Counter(l for c in min_clauses(clauses) for l in prop_symbols(c))
    return max(symbols, key=lambda symbol: scores[symbol]), True


def momsf(symbols, clauses, k=0):
    """
    MOMS alternative heuristic
    If f(x) the number of occurrences of the variable x in clauses with minimum size,
    we choose the variable maximizing [f(x) + f(-x)] * 2^k + f(x) * f(-x)
    Returns x if f(x) >= f(-x) otherwise -x
    """
    scores = Counter(l for c in min_clauses(clauses) for l in disjuncts(c))
    P = max(symbols,
            key=lambda symbol: (scores[symbol] + scores[~symbol]) * pow(2, k) + scores[symbol] * scores[~symbol])
    return P, True if scores[P] >= scores[~P] else False


def posit(symbols, clauses):
    """
    Freeman's POSIT version of MOMs
    Counts the positive x and negative x for each variable x in clauses with minimum size
    Returns x if f(x) >= f(-x) otherwise -x
    """
    scores = Counter(l for c in min_clauses(clauses) for l in disjuncts(c))
    P = max(symbols, key=lambda symbol: scores[symbol] + scores[~symbol])
    return P, True if scores[P] >= scores[~P] else False


def zm(symbols, clauses):
    """
    Zabih and McAllester's version of MOMs
    Counts the negative occurrences only of each variable x in clauses with minimum size
    """
    scores = Counter(l for c in min_clauses(clauses) for l in disjuncts(c) if l.op == '~')
    return max(symbols, key=lambda symbol: scores[~symbol]), True


def dlis(symbols, clauses):
    """
    DLIS (Dynamic Largest Individual Sum) heuristic
    Choose the variable and value that satisfies the maximum number of unsatisfied clauses
    Like DLCS but we only consider the literal (thus Cp and Cn are individual)
    """
    scores = Counter(l for c in clauses for l in disjuncts(c))
    P = max(symbols, key=lambda symbol: scores[symbol])
    return P, True if scores[P] >= scores[~P] else False


def dlcs(symbols, clauses):
    """
    DLCS (Dynamic Largest Combined Sum) heuristic
    Cp the number of clauses containing literal x
    Cn the number of clauses containing literal -x
    Here we select the variable maximizing Cp + Cn
    Returns x if Cp >= Cn otherwise -x
    """
    scores = Counter(l for c in clauses for l in disjuncts(c))
    P = max(symbols, key=lambda symbol: scores[symbol] + scores[~symbol])
    return P, True if scores[P] >= scores[~P] else False


def jw(symbols, clauses):
    """
    Jeroslow-Wang heuristic
    For each literal compute J(l) = \sum{l in clause c} 2^{-|c|}
    Return the literal maximizing J
    """
    scores = Counter()
    for c in clauses:
        for l in prop_symbols(c):
            scores[l] += pow(2, -len(c.args))
    return max(symbols, key=lambda symbol: scores[symbol]), True


def jw2(symbols, clauses):
    """
    Two Sided Jeroslow-Wang heuristic
    Compute J(l) also counts the negation of l = J(x) + J(-x)
    Returns x if J(x) >= J(-x) otherwise -x
    """
    scores = Counter()
    for c in clauses:
        for l in disjuncts(c):
            scores[l] += pow(2, -len(c.args))
    P = max(symbols, key=lambda symbol: scores[symbol] + scores[~symbol])
    return P, True if scores[P] >= scores[~P] else False


# ______________________________________________________________________________
# DPLL-Satisfiable [Figure 7.17]


def dpll_satisfiable(s, branching_heuristic=no_branching_heuristic):
    """Check satisfiability of a propositional sentence.
    This differs from the book code in two ways: (1) it returns a model
    rather than True when it succeeds; this is more useful. (2) The
    function find_pure_symbol is passed a list of unknown clauses, rather
    than a list of all clauses and the model; this is more efficient.
    >>> dpll_satisfiable(A |'<=>'| B) == {A: True, B: True}
    True
    """
    return dpll(conjuncts(to_cnf(s)), prop_symbols(s), {}, branching_heuristic)


def dpll(clauses, symbols, model, branching_heuristic=no_branching_heuristic):
    """See if the clauses are true in a partial model."""
    unknown_clauses = []  # clauses with an unknown truth value
    for c in clauses:
        val = pl_true(c, model)
        if val is False:
            return False
        if val is None:
            unknown_clauses.append(c)
    if not unknown_clauses:
        return model
    P, value = find_pure_symbol(symbols, unknown_clauses)
    if P:
        return dpll(clauses, remove_all(P, symbols), extend(model, P, value), branching_heuristic)
    P, value = find_unit_clause(clauses, model)
    if P:
        return dpll(clauses, remove_all(P, symbols), extend(model, P, value), branching_heuristic)
    P, value = branching_heuristic(symbols, unknown_clauses)
    return (dpll(clauses, remove_all(P, symbols), extend(model, P, value), branching_heuristic) or
            dpll(clauses, remove_all(P, symbols), extend(model, P, not value), branching_heuristic))


def find_pure_symbol(symbols, clauses):
    """Find a symbol and its value if it appears only as a positive literal
    (or only as a negative) in clauses.
    >>> find_pure_symbol([A, B, C], [A|~B,~B|~C,C|A])
    (A, True)
    """
    for s in symbols:
        found_pos, found_neg = False, False
        for c in clauses:
            if not found_pos and s in disjuncts(c):
                found_pos = True
            if not found_neg and ~s in disjuncts(c):
                found_neg = True
        if found_pos != found_neg:
            return s, found_pos
    return None, None


def find_unit_clause(clauses, model):
    """Find a forced assignment if possible from a clause with only 1
    variable not bound in the model.
    >>> find_unit_clause([A|B|C, B|~C, ~A|~B], {A:True})
    (B, False)
    """
    for clause in clauses:
        P, value = unit_clause_assign(clause, model)
        if P:
            return P, value
    return None, None


def unit_clause_assign(clause, model):
    """Return a single variable/value pair that makes clause true in
    the model, if possible.
    >>> unit_clause_assign(A|B|C, {A:True})
    (None, None)
    >>> unit_clause_assign(B|~C, {A:True})
    (None, None)
    >>> unit_clause_assign(~A|~B, {A:True})
    (B, False)
    """
    P, value = None, None
    for literal in disjuncts(clause):
        sym, positive = inspect_literal(literal)
        if sym in model:
            if model[sym] == positive:
                return None, None  # clause already True
        elif P:
            return None, None  # more than 1 unbound variable
        else:
            P, value = sym, positive
    return P, value


def inspect_literal(literal):
    """The symbol in this literal, and the value it should take to
    make the literal true.
    >>> inspect_literal(P)
    (P, True)
    >>> inspect_literal(~P)
    (P, False)
    """
    if literal.op == '~':
        return literal.args[0], False
    else:
        return literal, True


# ______________________________________________________________________________



# Expr functions for WumpusKB and HybridWumpusAgent

def facing_east(time):
    return Expr('FacingEast', time)


def facing_west(time):
    return Expr('FacingWest', time)


def facing_north(time):
    return Expr('FacingNorth', time)


def facing_south(time):
    return Expr('FacingSouth', time)


def wumpus(x, y):
    return Expr('W', x, y)


def pit(x, y):
    return Expr('P', x, y)


def breeze(x, y):
    return Expr('B', x, y)


def stench(x, y):
    return Expr('S', x, y)


def wumpus_alive(time):
    return Expr('WumpusAlive', time)


def have_arrow(time):
    return Expr('HaveArrow', time)


def percept_stench(time):
    return Expr('Stench', time)


def percept_breeze(time):
    return Expr('Breeze', time)


def percept_glitter(time):
    return Expr('Glitter', time)


def percept_bump(time):
    return Expr('Bump', time)


def percept_scream(time):
    return Expr('Scream', time)


def move_forward(time):
    return Expr('Forward', time)


def shoot(time):
    return Expr('Shoot', time)


def turn_left(time):
    return Expr('TurnLeft', time)


def turn_right(time):
    return Expr('TurnRight', time)


def ok_to_move(x, y, time):
    return Expr('OK', x, y, time)


def location(x, y, time=None):
    if time is None:
        return Expr('L', x, y)
    else:
        return Expr('L', x, y, time)


# Symbols

def implies(lhs, rhs):
    return Expr('==>', lhs, rhs)


def equiv(lhs, rhs):
    return Expr('<=>', lhs, rhs)


# Helper Function

def new_disjunction(sentences):
    t = sentences[0]
    for i in range(1, len(sentences)):
        t |= sentences[i]
    return t


# ______________________________________________________________________________


class WumpusKB(PropKB):
    """
    Create a Knowledge Base that contains the a temporal "Wumpus physics" and temporal rules with time zero.
    """

    def __init__(self, dimrow):
        super().__init__()
        self.dimrow = dimrow
        self.tell(~wumpus(1, 1))
        self.tell(~pit(1, 1))

        for y in range(1, dimrow + 1):
            for x in range(1, dimrow + 1):

                pits_in = list()
                wumpus_in = list()

                if x > 1:  # West room exists
                    pits_in.append(pit(x - 1, y))
                    wumpus_in.append(wumpus(x - 1, y))

                if y < dimrow:  # North room exists
                    pits_in.append(pit(x, y + 1))
                    wumpus_in.append(wumpus(x, y + 1))

                if x < dimrow:  # East room exists
                    pits_in.append(pit(x + 1, y))
                    wumpus_in.append(wumpus(x + 1, y))

                if y > 1:  # South room exists
                    pits_in.append(pit(x, y - 1))
                    wumpus_in.append(wumpus(x, y - 1))

                self.tell(equiv(breeze(x, y), new_disjunction(pits_in)))
                self.tell(equiv(stench(x, y), new_disjunction(wumpus_in)))

        # Rule that describes existence of at least one Wumpus
        wumpus_at_least = list()
        for x in range(1, dimrow + 1):
            for y in range(1, dimrow + 1):
                wumpus_at_least.append(wumpus(x, y))

        self.tell(new_disjunction(wumpus_at_least))

        # Rule that describes existence of at most one Wumpus
        for i in range(1, dimrow + 1):
            for j in range(1, dimrow + 1):
                for u in range(1, dimrow + 1):
                    for v in range(1, dimrow + 1):
                        if i != u or j != v:
                            self.tell(~wumpus(i, j) | ~wumpus(u, v))

        # Temporal rules at time zero
        self.tell(location(1, 1, 0))
        for i in range(1, dimrow + 1):
            for j in range(1, dimrow + 1):
                self.tell(implies(location(i, j, 0), equiv(percept_breeze(0), breeze(i, j))))
                self.tell(implies(location(i, j, 0), equiv(percept_stench(0), stench(i, j))))
                if i != 1 or j != 1:
                    self.tell(~location(i, j, 0))

        self.tell(wumpus_alive(0))
        self.tell(have_arrow(0))
        self.tell(facing_east(0))
        self.tell(~facing_north(0))
        self.tell(~facing_south(0))
        self.tell(~facing_west(0))

    def make_action_sentence(self, action, time):
        actions = [move_forward(time), shoot(time), turn_left(time), turn_right(time)]

        for a in actions:
            if action is a:
                self.tell(action)
            else:
                self.tell(~a)

    def make_percept_sentence(self, percept, time):
        # Glitter, Bump, Stench, Breeze, Scream
        flags = [0, 0, 0, 0, 0]

        # Things perceived
        if isinstance(percept, Glitter):
            flags[0] = 1
            self.tell(percept_glitter(time))
        elif isinstance(percept, Bump):
            flags[1] = 1
            self.tell(percept_bump(time))
        elif isinstance(percept, Stench):
            flags[2] = 1
            self.tell(percept_stench(time))
        elif isinstance(percept, Breeze):
            flags[3] = 1
            self.tell(percept_breeze(time))
        elif isinstance(percept, Scream):
            flags[4] = 1
            self.tell(percept_scream(time))

        # Things not perceived
        for i in range(len(flags)):
            if flags[i] == 0:
                if i == 0:
                    self.tell(~percept_glitter(time))
                elif i == 1:
                    self.tell(~percept_bump(time))
                elif i == 2:
                    self.tell(~percept_stench(time))
                elif i == 3:
                    self.tell(~percept_breeze(time))
                elif i == 4:
                    self.tell(~percept_scream(time))

    def add_temporal_sentences(self, time):
        if time == 0:
            return
        t = time - 1

        # current location rules
        for i in range(1, self.dimrow + 1):
            for j in range(1, self.dimrow + 1):
                self.tell(implies(location(i, j, time), equiv(percept_breeze(time), breeze(i, j))))
                self.tell(implies(location(i, j, time), equiv(percept_stench(time), stench(i, j))))
                s = list()
                s.append(equiv(location(i, j, time), location(i, j, time) & ~move_forward(time) | percept_bump(time)))
                if i != 1:
                    s.append(location(i - 1, j, t) & facing_east(t) & move_forward(t))
                if i != self.dimrow:
                    s.append(location(i + 1, j, t) & facing_west(t) & move_forward(t))
                if j != 1:
                    s.append(location(i, j - 1, t) & facing_north(t) & move_forward(t))
                if j != self.dimrow:
                    s.append(location(i, j + 1, t) & facing_south(t) & move_forward(t))

                # add sentence about location i,j
                self.tell(new_disjunction(s))

                # add sentence about safety of location i,j
                self.tell(equiv(ok_to_move(i, j, time), ~pit(i, j) & ~wumpus(i, j) & wumpus_alive(time)))

        # Rules about current orientation

        a = facing_north(t) & turn_right(t)
        b = facing_south(t) & turn_left(t)
        c = facing_east(t) & ~turn_left(t) & ~turn_right(t)
        s = equiv(facing_east(time), a | b | c)
        self.tell(s)

        a = facing_north(t) & turn_left(t)
        b = facing_south(t) & turn_right(t)
        c = facing_west(t) & ~turn_left(t) & ~turn_right(t)
        s = equiv(facing_west(time), a | b | c)
        self.tell(s)

        a = facing_east(t) & turn_left(t)
        b = facing_west(t) & turn_right(t)
        c = facing_north(t) & ~turn_left(t) & ~turn_right(t)
        s = equiv(facing_north(time), a | b | c)
        self.tell(s)

        a = facing_west(t) & turn_left(t)
        b = facing_east(t) & turn_right(t)
        c = facing_south(t) & ~turn_left(t) & ~turn_right(t)
        s = equiv(facing_south(time), a | b | c)
        self.tell(s)

        # Rules about last action
        self.tell(equiv(move_forward(t), ~turn_right(t) & ~turn_left(t)))

        # Rule about the arrow
        self.tell(equiv(have_arrow(time), have_arrow(t) & ~shoot(t)))

        # Rule about Wumpus (dead or alive)
        self.tell(equiv(wumpus_alive(time), wumpus_alive(t) & ~percept_scream(time)))

    def ask_if_true(self, query):
        return pl_resolution(self, query)

this is inputs.py:

EXAMPLE_INIT_INPUT = (  # This one corresponds to the first input example
    (3, 3),
    (0, 0),
    []
)

EXAMPLE_OBSERVATIONS = [  # This is the observation for the 4th input example when standing at (2, 1)
    ('vault', (2, 2)),
    ('dragon', (1, 1)),
    ('sulfur',)
]

CODES_NEW = {'passage': 0, 'dragon': 1, 'vault': 2, 'trap': 3, 'hollow_vault': 4, 'vault_trap': 5, 'dragon_trap': 6,
             'hollow_trap_vault': 7}

easy_inputs = [
    # {
    #     'Harry_start': (1, 0),
    #     'full_map': [
    #         [0, 0, 0],
    #         [0, 1, 0],
    #         [0, 4, 0]
    #     ]
    # },
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0],
            [0, 3, 0],
            [0, 4, 0]
        ]
    }
    # {
    #     'Harry_start': (0, 0),
    #     'full_map': [
    #         [0, 1, 0],
    #         [0, 0, 4],
    #         [0, 1, 0]
    #     ]
    # }
]

inputs = [
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0],
            [0, 0, 0],
            [0, 4, 0]
        ]
    },
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0],
            [0, 1, 0],
            [0, 4, 0]
        ]
    },
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0],
            [0, 3, 0],
            [0, 4, 0]
        ]
    },
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0],
            [0, 1, 0],
            [0, 0, 7]
        ]
    },
    {
        'Harry_start': (0, 0),
        'full_map': [
            [0, 0, 0, 0],
            [0, 0, 1, 3],
            [0, 6, 2, 4],
            [0, 0, 5, 0]
        ]
    },
    {
        'Harry_start': (3, 3),
        'full_map': [
            [0, 0, 0, 0],
            [0, 0, 1, 3],
            [0, 6, 2, 4],
            [0, 0, 5, 0]
        ]
    },


]

lectures and tutorials:
1. "Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Introduction to AI
Informed State-space Search
Reshef Meir
Slides by Carmel Domshlak
DD&S — Technion
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Heuristic search algorithms: systematic
Heuristic search algorithms are the most common and
overall most successful algorithms for deterministic
planning.
Popular systematic heuristic search algorithms:
greedy best-first search
A
∗
weighted A∗
IDA∗
depth-first branch-and-bound search
breadth-first heuristic search
. . .
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Heuristic search algorithms: local
Heuristic search algorithms are the most common and
overall most successful algorithms for deterministic
planning.
Popular heuristic local search algorithms:
hill-climbing
enforced hill-climbing
beam search
tabu search
genetic algorithms
simulated annealing
. . .
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Heuristic search: idea
goal init distance estimate distance estimate distance estimate distance estimate
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Required ingredients for heuristic search
A heuristic search algorithm requires one more operation
in addition to the definition of a search space.
Definition (heuristic function)
Let Σ be the set of nodes of a given search space.
A heuristic function or heuristic (for that search space) is a
function h : Σ → N0 ∪ {∞}.
The value h(σ) supposed to estimate the distance from
node σ to the nearest goal node.
Typically: h(σ)
def = h(state(σ))
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
What exactly is a heuristic estimate?
What does it mean that h “estimates the goal distance”?
For most heuristic search algorithms, h does not need to
have any strong properties for the algorithm to ‘work’ (=
return a correct solution).
However, the efficiency of the algorithm closely relates to
how accurately h reflects the actual goal distance.
For some algorithms, like A∗
, we can prove strong formal
relationships between properties of h and properties of the
algorithm (optimality, dominance, run-time for bounded
error, . . . )
For other search algorithms, “it works well in practice” is
often as good an analysis as one gets.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Perfect heuristic
Let Σ be the set of nodes of a given search space.
Definition (optimal/perfect heuristic)
The optimal or perfect heuristic of a search space is the
heuristic h
∗ which maps each search node σ to the length of a
shortest path from state(σ) to any goal state.
Note: h
∗
(σ) = ∞ iff no goal state is reachable from σ.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Properties of heuristics
A heuristic h is called
safe if for all σ ∈ Σ, h(σ) = ∞ implies h
∗
(σ) = ∞
goal-aware if h(σ) = 0 for all goal nodes σ ∈ Σ
admissible if h(σ) ≤ h
∗
(σ) for all nodes σ ∈ Σ
consistent if h(σ) ≤ h(σ
′
) + cost(σ, σ′
)
for all nodes σ, σ′ ∈ Σ such that σ
′
is a successor of σ
(limited Triangle Inequality)
Examples (h
∗
is driving distance):
h(σ) ≡ 0
h(σ) is Euclidean Distance to goal
h(σ) is real driving distance if going via Sibiu
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Properties of heuristics
A heuristic h is called
safe if for all σ ∈ Σ, h(σ) = ∞ implies h
∗
(σ) = ∞
goal-aware if h(σ) = 0 for all goal nodes σ ∈ Σ
admissible if h(σ) ≤ h
∗
(σ) for all nodes σ ∈ Σ
consistent if h(σ) ≤ h(σ
′
) + cost(σ, σ′
)
for all nodes σ, σ′ ∈ Σ such that σ
′
is a successor of σ
(limited Triangle Inequality)
Examples (h
∗
is driving distance):
h(σ) ≡ 0
h(σ) is Euclidean Distance to goal
h(σ) is real driving distance if going via Sibiu
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Greedy best-first search
Greedy best-first search (with duplicate detection)
open := new min-heap ordered by
(
σ
7→
h
(
σ))
open
.insert
(make-root-node
(init()))
closed :=
∅
while not open
.empty(): σ = open.pop-min()
if state
(
σ
)
∈/ closed:
closed := closed ∪ {state
(
σ
)
}
if is-goal
(state
(
σ)):
return extract-solution
(
σ
)
for each
⟨o, s⟩ ∈ succ
(state
(
σ)): σ′
:= make-node
(σ, o, s
)
if
h
(
σ
′
)
<
∞:
open
.insert
(
σ
′
)
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Planning trip to Bucharest with SLD heuristic
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
GBFS by example
Rimnicu Vilcea
Zerind
Arad
Sibiu
Arad Fagaras Oradea
Timisoara
Sibiu Bucharest
329 374
366 380 193
253 0
Rimnicu Vilcea
Zerind
Arad
Sibiu
Arad Fagaras Oradea
Timisoara
329 374
366 176 380 193
Zerind
Arad
Sibiu Timisoara
253 329 374
Arad
366
(a) The initial state
(b) After expanding Arad
(c) After expanding Sibiu
(d) After expanding Fagaras
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Properties of greedy best-first search
one of the three most commonly used algorithms for
satisficing planning
complete for safe heuristics (due to duplicate detection)
suboptimal unless h satisfies some very strong
assumptions (similar to being perfect)
invariant under all strictly monotonic transformations of h
(e. g., scaling with a positive constant or adding a
constant)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
A
∗
A
∗
(with duplicate detection and reopening)
open := new min-heap ordered by (σ 7→ f(σ) = g(σ) + h(σ))
open.insert(make-root-node(init()))
closed := ∅
distance := ∅
while not open.empty():
σ = open.pop-min()
if state(σ) ∈/ closed or g(σ) < distance(state(σ)):
closed := closed ∪ {state(σ)}
distance(state(σ)) := g(σ)
if is-goal(state(σ)):
return extract-solution(σ)
for each ⟨o, s⟩ ∈ succ(state(σ)):
σ
′
:= make-node(σ, o, s)
if h(σ
′
) < ∞:
open.insert(σ
′
)
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
A
∗
(one node maintained per state)
A
∗
(with duplicate detection and reopening)
open := new min-set-heap ordered by (σ 7→ f(σ) = g(σ) + h(σ))
open.insert(make-root-node(init()))
closed := ∅
distance := ∅
while not open.empty():
σ = open.pop-min()
if state(σ) ∈/ closed or g(σ) < distance(state(σ)):
closed := closed ∪ {state(σ)}
distance(state(σ)) := g(σ)
if is-goal(state(σ)):
return extract-solution(σ)
for each ⟨o, s⟩ ∈ succ(state(σ)):
σ
′
:= make-node(σ, o, s)
if h(σ
′
) < ∞:
open.insert(σ
′
) // override other nodes of s
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
A
∗ by example
(a) The initial state
(b) After expanding Arad
(c) After expanding Sibiu
Zerind
Arad
Sibiu Timisoara
393=140+253 447=118+329 449=75+374
Arad
366=0+366
(d) After expanding Rimnicu Vilcea
Zerind
Arad
Sibiu
Arad
Timisoara
Fagaras Oradea Rimnicu Vilcea
447=118+329 449=75+374
646=280+366 413=220+193 415=239+176 671=291+380
Zerind
Arad
Sibiu
Arad
Timisoara
Fagaras Oradea
447=118+329 449=75+374
646=280+366 415=239+176
Rimnicu Vilcea
Craiova Pitesti Sibiu
526=366+160 417=317+100 553=300+253
671=291+380

Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
A
∗ by example
Zerind
Arad
Sibiu
Arad
Timisoara
Sibiu Bucharest
Fagaras Oradea Rimnicu Vilcea
Craiova Pitesti Sibiu
Bucharest Craiova Rimnicu Vilcea
418=418+0
447=118+329 449=75+374
646=280+366
591=338+253 450=450+0 526=366+160 553=300+253
615=455+160 607=414+193
671=291+380
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Properties of A∗
the most commonly used algorithm for optimal planning
rarely used for satisficing planning
complete for safe heuristics
(even without duplicate detection)
optimal for admissible heuristics
even h ≡ 0?
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Optimality of Tree-Search A∗ with Admissible h
Standard proof
Theorem
A∗ with an admissible heuristic returns an optimal path.
Proof.
For any node σ, we denote by path(σ) the path from the root node to σ.
Suppose to the contrary that the algorithm returns a suboptimal plan via
extract-solution(ˆσ) for some node σˆ with state(ˆσ) = G (the path path(ˆσ) is
marked in blue arrows in the figure, and the state of every node appears as an
orange square).
Consider an arbitrary optimal solution path(σ
∗) (marked by red arrows). Clearly
the final node has state(σ
∗) = G.
We now consider the last step of the A∗algorithm run, when node σˆ was opened.
Consider all the nodes in the priority-queue at the beginning of this step (marked
by light blue in the figure).
We note that σˆ is in the queue (since indeed it was selected by the algorithm).
Let σ
′ be the first node on the optimal path that is not part path(ˆσ), then σ
′
is
also in the queue since it is a child of some node in path(ˆσ).
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Proof (cont.)
We argue that A∗ was supposed to open σ
′ before σˆ. Indeed:
f(ˆσ) = g(ˆσ) + h(ˆσ) = g(ˆσ) (since state(ˆσ) = G)
> g(σ
∗
) (since path(σ
∗
) is optimal and path(ˆσ) is not)
= g(σ
′
) + h
∗
(σ
′
) (we break the red path into parts)
≥ g(σ
′
) + h(σ
′
) = f(σ
′
) (h is admissible)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Weighted A∗
Weighted A∗
(with duplicate detection and reopening)
open := new min-heap ordered by (σ 7→ g(σ) + W · h(σ))
open.insert(make-root-node(init()))
closed := ∅
distance := ∅
while not open.empty():
σ = open.pop-min()
if state(σ) ∈/ closed or g(σ) < distance(state(σ)):
closed := closed ∪ {state(σ)}
distance(σ) := g(σ)
if is-goal(state(σ)):
return extract-solution(σ)
for each ⟨o, s⟩ ∈ succ(state(σ)):
σ
′
:= make-node(σ, o, s)
if h(σ
′
) < ∞:
open.insert(σ
′
)
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Properties of weighted A∗
The weight W ∈ R
+
0
is a parameter of the algorithm.
for W = 0, behaves like breadth-first search
for W = 1, behaves like A∗
for W → ∞, behaves like greedy best-first search
Properties:
one of the three most commonly used algorithms for
satisficing planning
for W > 1, can prove similar properties to A∗
, replacing
optimal with bounded suboptimal: generated solutions are
at most a factor W as long as optimal ones
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Hill-climbing
Hill-climbing
σ := make-root-node(init())
forever:
if is-goal(state(σ)):
return extract-solution(σ)
Σ
′
:= { make-node(σ, o, s) | ⟨o, s⟩ ∈ succ(state(σ)) }
σ := an element of Σ
′ minimizing h (random tie breaking)
can easily get stuck in local minima where immediate
improvements of h(σ) are not possible
many variations: tie-breaking strategies, restarts
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Enforced hill-climbing
Enforced hill-climbing: procedure improve
def improve(σ0):
queue := new fifo-queue
queue.push-back(σ0)
closed := ∅
while not queue.empty():
σ = queue.pop-front()
if state(σ) ∈/ closed:
closed := closed ∪ {state(σ)}
if h(σ) < h(σ0):
return σ
for each ⟨o, s⟩ ∈ succ(state(σ)):
σ
′
:= make-node(σ, o, s)
queue.push-back(σ
′
)
fail
; breadth-first search for more promising node than σ0
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Enforced hill-climbing (ctd.)
Enforced hill-climbing
σ := make-root-node(init())
while not is-goal(state(σ)):
σ := improve(σ)
return extract-solution(σ)
one of the three most commonly used algorithms for
satisficing planning
can fail if procedure improve fails (when the goal is
unreachable from σ0)
complete for undirected search spaces (where the
successor relation is symmetric) if h(σ) = 0 for all goal
nodes and only for goal nodes
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Classification: what works where in (deterministic)
planning?
uninformed vs. heuristic search:
For satisficing planning, heuristic search vastly
outperforms uninformed algorithms on most domains.
For optimal planning, heuristic search typically outperforms
uninformed algorithms, but an efficiently implemented
uninformed algorithm is not easy to beat in most domains.
systematic search vs. local search:
For satisficing planning, the most successful algorithms are
somewhere between the two extremes.
For optimal planning, systematic algorithms are required.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Where heuristics come from?
General idea
(Admissible) heuristic functions obtained as
(optimal) cost functions of relaxed problems
Examples
Euclidian distance in Path Finding
Manhattan distance in N-puzzle
Spanning Tree in Traveling Salesman Problem
Shortest Path in Job Shop Scheduling
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Example
Grid Search and Manhattan Distance
True distance h
∗
for different search states
Manhattan distance is based on the relaxation that ...?
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Example
8-Puzzle
2
Start State Goal State
51 3
4 6
7 8
5
1
2
3
4
6
7
8
5
A tile can move from square A to square B if A is adjacent to B and
B is blank ; solution distance h
∗
A tile can move from square A to square B if A is adjacent to B ;
manhattan distance heuristic h
MD
A tile can move from square A to square B ;
misplaced tiles heuristic h
MT
Here: h
∗
(s0) =?, hMD(s0) = 14, hMT (s0) = 6
In general, h
∗ ≥ hMD ≥ hMT
. (Why?)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Example
8-Puzzle
2
Start State Goal State
51 3
4 6
7 8
5
1
2
3
4
6
7
8
5
A tile can move from square A to square B if A is adjacent to B and
B is blank ; solution distance h
∗
A tile can move from square A to square B if A is adjacent to B ;
manhattan distance heuristic h
MD
A tile can move from square A to square B ;
misplaced tiles heuristic h
MT
Here: h
∗
(s0) =?, hMD(s0) = 14, hMT (s0) = 6
In general, h
∗ ≥ hMD ≥ hMT
. (Why?)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Dominance relation between admissible heuristics
Precision matters
Given two admissible heuristics h1, h2, if h2(σ) ≥ h1(σ) for all
search nodes σ, then h2 dominates h1 and is better for
optimizing search
Typical search costs (unit-cost action)
h
∗
(I) = 14 BFS ≈ 1,700,000 nodes
A
∗
(h1) ≈ 560 nodes
A
∗
(h2) ≈ 115 nodes
h
∗
(I) = 24 BFS ≈ 27,000,000,000 nodes
A
∗
(h1) ≈ 40,000 nodes
A
∗
(h2) ≈ 1,650 nodes
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Dominance relation between admissible heuristics
Precision matters
Given two admissible heuristics h1, h2, if h2(σ) ≥ h1(σ) for all
search nodes σ, then h2 dominates h1 and is better for
optimizing search
Combining admissible heuristics
For any admissible heuristics h1, . . . , hk,
h(σ) = maxk
i=1{hi(σ)}
is also admissible and dominates all individual hi
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Where do heuristics come from?
General idea
(Admissible) heuristic functions obtained as (optimal) cost
functions of relaxed problems
OK, but heuristic is yet another input to our agent!
Satisfactory for general solvers?
Satisfactory in special purpose solvers?
Towards domain-independent agents
How to get heuristics automatically?
Can such automatically derived heuristics dominate the
domain-specific heuristics crafted by hand?
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Heuristic
functions
Systematic
search
Local search
Heuristics
Where do heuristics come from?
General idea
(Admissible) heuristic functions obtained as (optimal) cost
functions of relaxed problems
OK, but heuristic is yet another input to our agent!
Satisfactory for general solvers?
Satisfactory in special purpose solvers?
Towards domain-independent agents
How to get heuristics automatically?
Can such automatically derived heuristics dominate the
domain-specific heuristics crafted by hand?"

2. Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Introduction to AI
Domain-independent planning
Reshef Meir
Slides by Carmel Domshlak
DD&S — Technion
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Reminder: Are we solver?
General idea
(Admissible) heuristic functions obtained as (optimal) cost
functions of relaxed problems
OK, but heuristic is yet another input to our agent!
Satisfactory for general solvers?
Satisfactory in special purpose solvers?
Towards domain-independent agents
How to get heuristics automatically?
Can such automatically derived heuristics dominate the
domain-specific heuristics crafted by hand?
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Model-based Problem Solving
We want planning to take the form of model-based solving
Problem =⇒ Language =⇒ Planner =⇒ Solution
1 models for defining, classifying, and understanding
problems
- what is a planning problem
- what is a solution (plan), and
- what is an optimal solution
2 languages for representing problems
3 algorithms for solving them
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Succinct representation of transition systems
We want a more compact representation of actions (than
as general relations)
possible because of symmetries and other regularities,
unavoidable because the relations are too big.
Represent different aspects of the world in terms of
different state variables.
; A state is a valuation of state variables.
Represent actions in terms of changes to the state
variables.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
State variables
The state of the world is described in terms of a finite set
of finite-valued state variables.
Example
hour: {0, . . . , 23} = 13
minute: {0, . . . , 59} = 55
location: {51, 52, 82, 101, 102} = 101
weather: {sunny, cloudy,rainy} = cloudy
holiday: {T, F} = F
Actions change the values of the state variables.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Blocks world with state variables
State variables:
location-of-A: {B, C,table}
location-of-B: {A, C,table}
location-of-C: {A, B,table}
Example
s(location-of-A) = table
s(location-of-B) = A
s(location-of-C) = table A
B
C
Not all valuations correspond to an intended blocks world
state, e. g. s such that s(location-of-A) = B and
s(location-of-B) = A.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Blocks world with Boolean state variables
Example
s(A-on-B) = 0
s(A-on-C) = 0
s(A-on-table) = 1
s(B-on-A) = 1
s(B-on-C) = 0
s(B-on-table) = 0
s(C-on-A) = 0
s(C-on-B) = 0
s(C-on-table) = 1
A
B
C
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Deterministic planning tasks
Definition (deterministic planning task)
A deterministic planning task is a 4-tuple Π = ⟨V, I, A, G⟩
V is a finite set of state variables,
I is an initial state over V ,
A is a finite set of actions over V , and
G is a formula over V describing the goal states.
in what follows: partial assignment to V
; Mapping planning tasks to transition systems
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Planning Languages
Key issue
Models represented implicitly in a declarative language
Play two roles
specification: concise model description
computation: reveal useful info about problem’s structure
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
The STRIPS language
A problem in STRIPS is a tuple ⟨P, A, I, G⟩
P stands for a finite set of atoms (boolean vars)
I ⊆ P stands for initial situation
G ⊆ P stands for goal situation
A is a finite set of actions a specified via
pre(a), add(a), and del(a), all subsets of P
States are collections of atoms
An action a is applicable in a state s iff pre(a) ⊆ s
Applying an applicable action a at s results in
s
′ = (s \ del(a)) ∪ add(a)
Example (board)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
State variables
Tasks
Action Languages
Obtaining
heuristics
Concrete
Heuristics
Why STRIPS is interesting
STRIPS actions are particularly simple, yet expressive
enough to capture general planning problems.
In particular, STRIPS planning is no easier than general
planning problems.
Many algorithms in the planning literature are easier to
present in terms of STRIPS .
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
A simple heuristic for deterministic planning
STRIPS (Fikes & Nilsson, 1971) used the number of state
variables that differ in current state s and a STRIPS goal
G = {g1, . . . , gk}:
h(s) := |G \ s|.
Intuition: more true goal literals ; closer to the goal
; STRIPS heuristic (properties?)
Example
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Criticism of the STRIPS heuristic
What is wrong with the STRIPS heuristic?
quite uninformative:
the range of heuristic values in a given task is small;
typically, many successors have the same estimate
very sensitive to reformulation:
can easily transform any planning task into an equivalent
one where h(s) = 1 for all non-goal states (how?)
ignores almost all problem structure:
heuristic value does not depend on the set of actions!
; need a better, principled way of coming up with heuristics
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Coming up with heuristics in a principled way
General procedure for obtaining a heuristic
Solve an easier version of the problem.
Two common methods:
relaxation: consider less constrained version of the problem
abstraction: consider smaller version of real problem
Both have been very successfully applied in planning
(separately and together).
We consider relaxation.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxing a problem
How do we relax a problem?
Example (Route planning for a road network)
The road network is formalized as a weighted graph over points
in the Euclidean plane. The weight of an edge is the road
distance between two locations.
A relaxation drops constraints of the original problem.
Example (Relaxation for route planning)
Use the Euclidean distance p
|x1 − y1|
2 + |x2 − y2|
2 as a
heuristic for the road distance between (x1, x2) and (y1, y2)
This is a lower bound on the road distance (; admissible).
; We drop the constraint of having to travel on roads.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxations for planning
Relaxation is a general technique for heuristic design:
Straight-line heuristic (route planning): Ignore the fact
that one must stay on roads.
Manhattan heuristic (15-puzzle): Ignore the fact that one
cannot move through occupied tiles.
We want to apply the idea of relaxations to planning.
Informally, we want to ignore bad side effects of applying
actions.
Example (8-puzzle)
If we move a tile from x to y, then the good effect is
(in particular) that x is now free.
The bad effect is that y is not free anymore, preventing us for
moving tiles through it.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxed planning tasks: idea
Definition
A planning problem is Monotone if no action has a bad effect.
In STRIPS, good and bad effects are easy to distinguish:
Effects that make atoms true are good (why?)
(add effects).
Effects that make atoms false are bad
(delete effects).
Idea for a monotone heuristic: Ignore all delete effects.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxed planning tasks: idea
Definition
A planning problem is Monotone if no action has a bad effect.
In STRIPS, good and bad effects are easy to distinguish:
Effects that make atoms true are good (why?)
(add effects).
Effects that make atoms false are bad
(delete effects).
Idea for a monotone heuristic: Ignore all delete effects.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxed planning tasks
Definition (relaxation of actions)
The relaxation a
+ of a STRIPS action
a = ⟨pre(a), add(a), del(a)⟩ is the action
a
+ = ⟨pre(a), add(a), ∅⟩.
Definition (relaxation of planning tasks)
The relaxation Π+ of a STRIPS planning task Π = ⟨P, A, I, G⟩
is the planning task Π+ := ⟨P, {a
+ | a ∈ A}, I, G⟩.
Definition (relaxation of action sequences)
The relaxation of an action sequence ρ = a1 . . . an is the action
sequence ρ
+ := a1
+ . . . an
+.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Relaxed planning tasks: terminology
STRIPS planning tasks without delete effects are called
relaxed planning tasks.
Plans for relaxed planning tasks are called relaxed plans.
If Π is a STRIPS planning task and ρ
+ is a plan for Π+,
then ρ
+ is called a relaxed plan for Π.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Example: Logistics
a = ⟨pre(a), add(a), del(a)⟩
Drive(X, Y ) = ⟨{at(T, X)}, {at(T, Y )}, {at(T, X)}⟩
Load(A, X) =
⟨{at(T, X), at(A, X), clear(T)}, {in(A, T)}, {at(A, X), clear(T)}⟩
UnLoad(A, X) = ⟨{at(T, X), in(A, T)}, {at(A, X), clear(T)}, {in(A, T)}⟩
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Example: Logistics
Initial state I: {at(A, Lef t), at(T, Lef t), at(B, Right)}
f (I, Drive(Lef t, Right)) =
{at(A, Lef t), at(T, Right), at(B, Right)}
f

I, Drive(Lef t, Right)
+

=
{at(A, Lef t), at(T, Lef t), at(T, Right), at(B, Right)}
f (I,⟨Drive(Lef t, Right), Load(A, Lef t)⟩) is undefined
f

I,⟨Drive(Lef t, Right)
+, Load(A, Lef t)
+⟩

=
{at(A, Lef t), at(T, Lef t), at(T, Right), at(B, Right),in(A, T
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Example: 8-Puzzle
1 2 3
6 7 9
4 8
1 2 3
4 6
7 8 9
A tile can move from square A to square B if A is adjacent
to B and B is blank - solution distance h
∗
A tile can move from square A to square B if A is adjacent
to B - manhattan distance heuristic hMD
A tile can move from square A to square B if A is adjacent
to B and B is blank; in effect, the tile is at both A and B,
and both A and B are blank - h
+
Here: h
∗
(s0) = 8, hMD(s0) = 6, h
+(s0) =???
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Example: 8-Puzzle 1 2 3 6 7 9 4 8
1
2
3
4
6
7
8
9
Optimal MD plan: 1 move(t9, p6, p9) 2 move(t7, p5, p8) 3 move(t6, p4, p5) 4 move(t6, p5, p6) 5 move(t4, p7, p4) 6 move(t7, p8, p7)
Optimal relaxed plan: 1 move(t9, p6, p9) 2 move(t8, p8, p9) 3 move(t7, p5, p8) 4 move(t6, p4, p5) 5 move(t6, p5, p6) 6 move(t4, p7, p4) 7 move(t7, p8, p7)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Example: 8-Puzzle
1 2 3
6 7 9
4 8
1 2 3
4 6
7 8 9
Optimal MD plan:
1 move(t9, p6, p9)
2 move(t7, p5, p8)
3 move(t6, p4, p5)
4 move(t6, p5, p6)
5 move(t4, p7, p4)
6 move(t7, p8, p7)
Optimal relaxed plan:
1 move(t9, p6, p9)
2 move(t8, p8, p9)
3 move(t7, p5, p8)
4 move(t6, p4, p5)
5 move(t6, p5, p6)
6 move(t4, p7, p4)
7 move(t7, p8, p7)
So h
∗
(s0) = 8, hMD(s0) = 6, h
+(s0) = 7(> hMD!)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
8-Puzzle: h
+ vs. h
MD
1 2 3
6 7 9
4 8
1 2 3
4 6
7 8 9
h
+ dominates hMD
The goal is given as a conjunction of at(ti
, pj ) atoms
Achieving each single one of them takes at least as many
steps as the respective tile’s Manhattan distance
Each action moves a single tile only
And we have just seen that h
+ strictly dominates hMD
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Dominating states
A state s
′ dominates another state s iff s ⊆ s
′
.
Lemma (relaxation)
Let s be a state, let s
′ be a state that dominates s,
and let ρ be an action sequence which is applicable in s.
Then ρ
+ is applicable in s
′
and appρ+ (s
′
) dominates appρ
(s).
Moreover, if ρ leads to a goal state from s, then ρ
+ leads to a
goal state from s
′
.
Proof.
The “moreover” part is immediate from appρ+ (s
′
) dominating
appρ
(s). Prove the rest by induction over the length of ρ.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Consequences of the relaxation lemma
Corollary (relaxation leads to dominance and preserves plans)
Let ρ be an action sequence which is applicable in state s.
Then ρ
+ is applicable in s and appρ+ (s) dominates appρ
(s).
If ρ is a plan for Π, then ρ
+ is a plan for Π+.
Proof.
Apply relaxation lemma with s
′ = s.
; Relaxations of plans are relaxed plans.
; Relaxations are no harder to solve than the original task.
; Optimal relaxed plans are never longer than optimal plans
for original tasks.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Consequences of the relaxation lemma (ctd.)
Corollary (relaxation preserves dominance)
Let s be a state, let s
′ be a state that dominates s,
and let ρ
+ be a relaxed action sequence applicable in s.
Then ρ
+ is applicable in s
′
and appρ+ (s
′
) dominates appρ+ (s).
Proof.
Apply relaxation lemma with ρ
+ for ρ, noting that
(ρ
+)
+ = ρ
+.
; If there is a relaxed plan starting from state s, the same
plan can be used starting from a dominating state s
′
.
; Making a transition to a dominating state never hurts in
relaxed planning tasks.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Monotonicity of relaxed planning tasks
We need one final property before we can provide an algorithm
for solving relaxed planning tasks.
Lemma (monotonicity)
Let a
+ = ⟨pre(a), add(a), ∅⟩ be a relaxed action and let s be a
state in which a
+ is applicable.
Then appa+ (s) dominates s.
Proof.
Since relaxed actions only have positive effects, we have
s ⊆ s ∪ add(a) = appa+ (s).
; Together with our previous results, this means that
making a transition in a relaxed planning task never hurts.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Greedy algorithm for relaxed planning tasks
The relaxation and monotonicity lemmas suggest the following
algorithm for solving relaxed planning tasks:
Greedy planning algorithm for ⟨P, A+, I, G⟩
s := I
ρ
+ := ϵ
forever:
if G ⊆ s:
return ρ
+
else if there is an action a
+ ∈ A+ applicable in s
with appa+ (s) ̸= s:
Append such an action a
+ to ρ
+.
s := appa+ (s)
else:
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Correctness of the greedy algorithm
The algorithm is sound:
If it returns a plan, this is indeed a correct solution.
If it returns “unsolvable”, the task is indeed unsolvable
Upon termination, there clearly is no relaxed plan from s.
By iterated application of the monotonicity lemma, s
dominates I.
By the relaxation lemma, there is no solution from I.
What about completeness (termination) and runtime?
Each iteration of the loop adds at least one atom to s.
This guarantees termination after at most |P| iterations.
Thus, the algorithm can clearly be implemented to run in
polynomial time.
A good implementation runs in O(∥Π∥).
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Using the greedy algorithm as a heuristic
We can apply the greedy algorithm within heuristic search:
In a search node σ, solve the relaxation of the planning
task with state(σ) as the initial state.
Set hˆ+(σ) to the length of the generated relaxed plan.
Note that hˆ+ ̸= h
+ (which is larger?)
Is hˆ+ an admissible heuristic?
Yes if the relaxed plans are optimal (due to the plan
preservation corollary).
However, usually they are not, because our greedy
planning algorithm is very poor.
(What about safety? Goal-awareness? Consistency?)
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
The set cover problem
To obtain an admissible heuristic, we need to generate optimal
relaxed plans. Can we do this efficiently?
This question is related to the following problem:
Problem (set cover)
Given: a finite set U, a collection of subsets C = {C1, . . . , Cn}
with Ci ⊆ U for all i ∈ {1, . . . , n}, and a natural number K.
Question: Does there exist a set cover of size at most K, i. e.,
a subcollection S = {S1, . . . , Sm} ⊆ C with S1 ∪ · · · ∪ Sm = U
and m ≤ K?
The following is a classical result from complexity theory:
Theorem
The set cover problem is NP-complete.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Hardness of optimal relaxed planning
Theorem (optimal relaxed planning is hard)
The problem of deciding whether a given relaxed planning task
has a plan of length at most K is NP-complete.
Proof.
For membership in NP, guess a plan and verify. It is sufficient
to check plans of length at most |P|, so this can be done in
nondeterministic polynomial time.
For hardness, we reduce from the set cover problem.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Hardness of optimal relaxed planning (ctd.)
Proof (ctd.)
Given a set cover instance ⟨U, C, K⟩, we generate the following
relaxed planning task Π+ = ⟨P, I, A+, G⟩:
P = U
I = ∅ ≡ I = {p = 0 | p ∈ P}
A+ = {⟨pre = ∅, add = Ci
, del = ∅⟩ | Ci ∈ C}
G = U
If S is a set cover, the corresponding actions form a plan.
Conversely, each plan induces a set cover by taking the subsets
corresponding to the actions. Clearly, there exists a plan of
length at most K iff there exists a set cover of size K.
Moreover, Π+ can be generated from the set cover instance in
polynomial time, so this is a polynomial reduction.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Using relaxations in practice
How can we use relaxations for heuristic planning in practice?
Different possibilities:
Implement an optimal planner for relaxed planning tasks
and use its solution lengths as an estimate, even though it
is NP-hard.
; h
+ heuristic (not that realistic. why?)
Use the greedy algorithm
; hˆ+ heuristic
Do not actually solve the relaxed planning task, but
compute an estimate of its difficulty in a different way.
; hmax heuristic, hadd heuristic
Compute a solution for relaxed planning tasks which is not
necessarily optimal, but “reasonable”.
; hFF heuristic
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Using relaxations in practice
How can we use relaxations for heuristic planning in practice?
Different possibilities:
Implement an optimal planner for relaxed planning tasks
and use its solution lengths as an estimate, even though it
is NP-hard.
; h
+ heuristic (not that realistic. why?)
Use the greedy algorithm
; hˆ+ heuristic
Do not actually solve the relaxed planning task, but
compute an estimate of its difficulty in a different way.
; hmax heuristic, hadd heuristic
Compute a solution for relaxed planning tasks which is not
necessarily optimal, but “reasonable”.
; hFF heuristic
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Using relaxations in practice
How can we use relaxations for heuristic planning in practice?
Different possibilities:
Implement an optimal planner for relaxed planning tasks
and use its solution lengths as an estimate, even though it
is NP-hard.
; h
+ heuristic (not that realistic. why?)
Use the greedy algorithm
; hˆ+ heuristic
Do not actually solve the relaxed planning task, but
compute an estimate of its difficulty in a different way.
; hmax heuristic, hadd heuristic
Compute a solution for relaxed planning tasks which is not
necessarily optimal, but “reasonable”.
; hFF heuristic
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
STRIPS heuristic
Relaxation heuristics
The relaxation
lemma
Greedy algorithm
Optimality
Discussion
Concrete
Heuristics
Using relaxations in practice
How can we use relaxations for heuristic planning in practice?
Different possibilities:
Implement an optimal planner for relaxed planning tasks
and use its solution lengths as an estimate, even though it
is NP-hard.
; h
+ heuristic (not that realistic. why?)
Use the greedy algorithm
; hˆ+ heuristic
Do not actually solve the relaxed planning task, but
compute an estimate of its difficulty in a different way.
; hmax heuristic, hadd heuristic
Compute a solution for relaxed planning tasks which is not
necessarily optimal, but “reasonable”.
; hFF heuristic
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Reminder: Greedy algorithm for relaxed planning
tasks
Greedy planning algorithm for ⟨P, A+, I, G⟩
s := I
ρ
+ := ϵ
forever:
if G ⊆ s:
return ρ
+
else if there is an action a
+ ∈ A+ applicable in s
with appa+ (s) ̸= s:
Append such an action a
+ to ρ
+.
s := appa+ (s)
else:
return unsolvable
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Graphical “interpretation”: Relaxed planning
graphs
Build a layered reachability graph P0, A0, P1, A1, . . .
P0 = {p ∈ I}
Ai = {a ∈ A | pre(a) ⊆ Pi}
Pi+1 = Pi ∪ {p ∈ add(a) | a ∈ Ai}
Terminate when G ⊆ Pi
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example
P
=
{a, b, c, d, e, f, g, h
}
I
=
{
a
}
G
=
{c, d, e, f, g
}
a
1
= ⟨{
a
}
,
{b, c
}
, ∅⟩
a
2
= ⟨{a, c
}
,
{
d
}
, ∅⟩
a
3
= ⟨{b, c
}
,
{
e
}
, ∅⟩
a
4
= ⟨{
b
}
,
{
f
}
, ∅⟩
a
5
= ⟨{
d
}
,
{e, f
}
, ∅⟩
a
6
= ⟨{
d
}
,
{
g
}
, ∅⟩
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
RPG1(Π+)
a
1
b
1
c
1
a1
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
RPG1(Π+)
a
1
b
1
c
1
a1
RPG2(Π+)
a
2
b
2
c
2
d
2
e
2
f
2
a1
a2
a3
a4
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
RPG1(Π+)
a
1
b
1
c
1
a1
RPG2(Π+)
a
2
b
2
c
2
d
2
e
2
f
2
a1
a2
a3
a4
RPG3(Π+)
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a1
a2
a3
a4
a5
a6
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
RPG1(Π+)
a
1
b
1
c
1
a1
RPG2(Π+)
a
2
b
2
c
2
d
2
e
2
f
2
a1
a2
a3
a4
RPG3(Π+)
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a1
a2
a3
a4
a5
a6
c
3
d
3
e
3
f
3
g
3
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Running example: Relaxed planning graph
RPG0(Π+)
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
RPG1(Π+)
a
1
b
1
c
1
a1
RPG2(Π+)
a
2
b
2
c
2
d
2
e
2
f
2
a1
a2
a3
a4
RPG3(Π+)
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a1
a2
a3
a4
a5
a6
G
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Generic relaxed planning graph heuristics
Computing heuristics from relaxed planning graphs
def generic-rpg-heuristic(⟨P, I, O, G⟩, s):
Π+ := ⟨P, s, O+, G⟩
for k ∈ {0, 1, 2, . . . }:
rpg := RPGk(Π+)
if G ⊆ Pk:
Annotate nodes of rpg.
if termination criterion is true:
return heuristic value from annotations
else if k = |P|:
return ∞
; generic template for heuristic functions
; to get concrete heuristic: fill in highlighted parts
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Concrete examples for the generic heuristic
Many planning heuristics fit the generic template:
max heuristic hmax
additive heuristic hadd
FF heuristic hFF
...
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Forward cost heuristics
The simplest relaxed planning graph heuristics are
forward cost heuristics.
Examples: hmax, hadd
Here, node annotations are cost values (natural numbers).
The cost of a node estimates how expensive (in terms of
required operators) it is to make this node true.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Forward cost heuristics: fitting the template
Forward cost heuristics
Computing annotations:
Propagate cost values bottom-up using a combination rule
for action nodes and a combination rule for proposition
nodes.
At action nodes, add 1 after applying combination rule.
Termination criterion:
stability: terminate if Pk = Pk−1 and cost for each
proposition node p
k ∈ Pk equals cost for p
k−1 ∈ Pk−1
Heuristic value:
The heuristic value is the cost of the auxiliary goal node.
Different forward cost heuristics only differ in their choice
of combination rules.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
The max heuristic hmax (again)
Forward cost heuristics: max heuristic hmax
Combination rule for action / goal nodes:
cost(a) = max({cost(p1), . . . , cost(pk)}) (plus 1 at action
nodes)
(with max(∅) := 0)
Combination rule for proposition nodes:
cost(p) = min({cost(a1), . . . , cost(ak)})
In both cases, {x1, . . . , xk} is the set of immediate
predecessors of A or P.
Intuition:
Action rule: If we have to achieve several preconditions,
estimate this by the most expensive cost.
Proposition rule: If we have a choice how to achieve a
proposition, pick the cheapest possibility.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
12
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1222
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1222
011222
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1222
011222
122233
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1222
011222
122233
0112223
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1222
011222
122233
0112223
3
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
The additive heuristic
Forward cost heuristics: additive heuristic hadd
Combination rule for action / goal nodes:
cost(a) = cost(p1) + . . . + cost(pk) (plus 1 at action
nodes)
(with P(∅) := 0)
Combination rule for proposition nodes:
cost(p) = min({cost(a1), . . . , cost(ak)})
Intuition:
Action rule: If we have to achieve several preconditions,
estimate this by the cost of achieving each in isolation.
Proposition rule: If we have a choice how to achieve a
proposition, pick the cheapest possibility.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
12
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1232
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1232
011232
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1232
011232
123233
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1232
011232
123233
0112323
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
0
1
011
1232
011232
123233
0112323
11
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Remarks on hadd
hadd is safe and goal-aware.
Unlike hmax, hadd is a very informative heuristic in many
planning domains.
Q: Intuitively, when it will be informative?
The price for this is that it is not admissible (and hence
also not consistent), so not suitable for optimal planning.
In fact, it almost always overestimates the h
+ value
because it does not take positive interactions into account.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
FF heuristic: fitting the template
The FF heuristic hFF
Computing annotations:
Annotations are Boolean values, computed top-down.
A node is marked when its annotation is set to 1 and
unmarked if it is set to 0. Initially, the goal node is
marked, and all other nodes are unmarked.
We say that an action node is justified if all its true
immediate predecessors are marked, and that a proposition
node is justified if at least one of its immediate
predecessors is marked.
. . .
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
FF heuristic: fitting the template (ctd.)
The FF heuristic hFF (ctd.)
Computing annotations:
. . .
Apply these rules until all marked nodes are justified:
1 Mark all immediate predecessors of a marked unjustified
ACTION (or GOAL) node.
2 Mark the immediate predecessor of a marked unjustified
PROP node with only one immediate predecessor.
3 Mark an immediate predecessor of a marked unjustified
PROP node connected via an idle arc.
4 Mark any immediate predecessor of a marked unjustified
PROP node.
The rules are given in priority order: earlier rules are
preferred if applicable.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
FF heuristic: fitting the template (ctd.)
The FF heuristic hFF (ctd.)
Termination criterion:
Always terminate at first layer where goal node is true.
Heuristic value:
The heuristic value is the number of marked action nodes.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
G
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MG
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMM
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMM
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
M
J
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
M
J
JJJ
MM
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
M
J
JJJ
MMJJ
M
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
M
J
JJJ
MMJJ
MJ
M
J
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template hmax hadd hFF
Comparison &
practice
Running example:
hFF
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
a
3
b
3
c
3
d
3
e
3
f
3
g
3
h
3
a
1
b
1
c
1
a
1
a
2
b
2
c
2
d
2
e
2
f
2
a
1
a
2
a
3
a
4
a
3
b
3
c
3
d
3
e
3
f
3
g
3
a
1
a
2
a
3
a
4
a
5
a
6
MGJ
MMMMMJ
M
JJJJ
J
MMMMJJJ
MMM
M
J
JJJ
MMJJ
MJ
M
J
JJJ
J
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Remarks on hFF
Like hadd, hFF is safe and goal-aware, but neither
admissible nor consistent.
Always more accurate than hadd with respect to h
+.
Marked actions define a relaxed plan.
hFF can be computed in linear time.
The hFF value depends on tie-breaking when the marking
rules allow several possible choices, so hFF is not
well-defined without specifying the tie-breaking rule.
The best implementations of FF use additional rules of
thumb to try to reduce the size of the generated relaxed
plan.
Introduction
to AI
Reshef Meir
Slides by
Carmel
Domshlak
Introduction
Problem
specification
Obtaining
heuristics
Concrete
Heuristics
Template
hmax
hadd
hFF
Comparison &
practice
Comparison of relaxation heuristics
Relationship between relaxation heuristics
Let s be a state of planning task ⟨P, I, O, G⟩. Then:
hmax(s) ≤ h
+(s) ≤ h
∗
(s)
hmax(s) ≤ h
+(s) ≤ hFF(s) ≤ hadd(s)
h
∗
and hFF are pairwise incomparable
h
∗
and hadd are incomparable
Moreover, h
+, hmax, hadd, and hFF assign ∞ to the same set
of states.
Note: For inadmissible heuristics, dominance is in general
neither desirable nor undesirable. For relaxation heuristics, the
objective is usually to get as close to h
+ as possible."

3. "Principles of AI (Planning)
6. Planning with STRIPS
William Davidson Faculty of Industrial Engineering and Management
Technion - Israel Institute of Technology
Real World: Problem to solve
World description (State space)
Legal moves (Operators)
Initial position (Initial state)
Desired outcome (Goal states)
Real World Example I
There is a table T, a crane C and n blocks. Each block can be
either on table, in crane, or on one other block. Crane can pick
up a block from the table, if it isn’t holding any block, it can
drop a block on table, if it is holding that block, it can stack
block x on top of block y, if it is holding block x and there is
no block on top of block y, and it can unstack block x from
block y into the crane, if it isn’t holding any block, and there is
no block on top of block x. Initially the blocks are stacked into
a tower 1 . . . n, and we want to swap the lowest two blocks,
n − 1 and n.
Real World Example I
World description
There is a table T, a crane C and n blocks. Each block can be
either on table, in crane, or on one other block
Operators
Crane can pick up a block from the table, if it isn’t holding any
block, it can drop a block on table, if it is holding that block, it
can stack block x on top of block y, if it is holding block x and
there is no block on top of block y, and it can unstack block x
from block y into the crane, if it isn’t holding any block, and
there is no block on top of block x
Initial State
Initially the blocks are stacked into a tower 1 . . . n
Goal
We want to swap the lowest two blocks, n − 1 and n
STRIPS Encoding
Planning task in STRIPS is a quadruple hP, O, I, Gi:
P: finite set of predicates
O: finite set of operators of form hpre, add, deli
O: (preconditions/add effects/delete effects: subsets of
predicates)
I: initial state (subset of predicates, others assumed to be
false)
G: goal description (subset of predicates)
STRIPS: Problem definition
Predicates
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
(on ?x, ?y) — Block ?x is directly on block ?y
(ontable ?x) — Block ?x is on table
(clear ?x) — There is no block above block ?x
(handempty) — The crane is empty
(holding ?x) — The crane is holding block ?x
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up block ?x from table
Drop block ?x on table
Unstack block ?x from block ?y
Stack block ?x on block ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up block ?x from table
Pick-up(?x):
Preconditions:
h(clear ?x),(ontable ?x),(handempty)i
Add Effects:
h(holding ?x)i
Delete Effects:
h(clear ?x),(ontable ?x),(handempty)i
Drop block ?x on table
Unstack block ?x from block ?y
Stack block ?x on block ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up block ?x from table
Drop block ?x on table
Drop(?x):
Preconditions:
h(holding ?x)i
Add Effects:
h(clear ?x),(ontable ?x),(handempty)i
Delete Effects:
h(holding ?x)i
Unstack block ?x from block ?y
Stack block ?x on block ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up block ?x from table
Drop block ?x on table
Unstack block ?x from block ?y
Unstack(?x, ?y):
Preconditions:
h(on ?x, ?y),(clear ?x),(handempty)i
Add Effects:
h(holding ?x),(clear ?y)i
Delete Effects:
h(on ?x, ?y),(clear ?x),(handempty)i
Stack block ?x on block ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up block ?x from table
Drop block ?x on table
Unstack block ?x from block ?y
Stack block ?x on block ?y
Stack(?x, ?y):
Preconditions:
h(holding ?x),(clear ?y)i
Add Effects:
h(clear ?x),(on ?x, ?y),(handempty)i
Delete Effects:
h(holding ?x),(clear ?y)i
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Initially we have
(ontable n),(handempty),(clear 1)
(on 1, 2), . . . ,(on n−1, n)
Goal
STRIPS: Problem definition
Predicates
Operators
Initial State
In goal we demand
(on 1, 2), . . . ,(on n−3, n−2)
(on n−2, n),(on n, n−1)
Real World Example II
Sliding Tile Puzzle consists of a N × N board with b tiles
missing. The object of the puzzle is to move tiles from their
initial position to the goal position. A legal move is a move
up/down/lef/right within board limits to the position of some
missing tile.
STRIPS: Problem definition
Predicates
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
(at ?t ?x ?y) — Tile ?t location is (?x, ?y).
(blank ?x ?y) — Blank tile location is (?x, ?y).
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Move tile ?t up from (i, j) ∈ {2 . . . N} × {1 . . . N}
Move tile ?t down from (i, j) ∈ {1 . . . N-1} × {1 . . . N}
Move tile ?t left from (i, j) ∈ {1 . . . N} × {2 . . . N}
Move tile ?t right from (i, j) ∈ {1 . . . N} × {1 . . . N-1}
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Move tile ?t up from (i, j) ∈ {2 . . . N} × {1 . . . N}
Move-Up(?t, i, j):
Preconditions:
h(blank i-1 j),(at ?t i j)i
Add Effects:
h(blank i j),(at ?t i-1 j)i
Delete Effects:
h(blank i-1 j),(at ?t i j)i
Move tile ?t down from (i, j) ∈ {1 . . . N-1} × {1 . . . N}
Move tile ?t left from (i, j) ∈ {1 . . . N} × {2 . . . N}
Move tile ?t right from (i, j) ∈ {1 . . . N} × {1 . . . N-1}
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Move tile ?t up from (i, j) ∈ {2 . . . N} × {1 . . . N}
Move tile ?t down from (i, j) ∈ {1 . . . N-1} × {1 . . . N}
Move-Down(?t, i, j):
Preconditions:
h(blank i+1 j),(at ?t i j)i
Add Effects:
h(blank i j),(at ?t i+1 j)i
Delete Effects:
h(blank i+1 j),(at ?t i j)i
Move tile ?t left from (i, j) ∈ {1 . . . N} × {2 . . . N}
Move tile ?t right from (i, j) ∈ {1 . . . N} × {1 . . . N-1}
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Move tile ?t up from (i, j) ∈ {2 . . . N} × {1 . . . N}
Move tile ?t down from (i, j) ∈ {1 . . . N-1} × {1 . . . N}
Move tile ?t left from (i, j) ∈ {1 . . . N} × {2 . . . N}
Move-Left(?t, i, j):
Preconditions:
h(blank i j-1),(at ?t i j)i
Add Effects:
h(blank i j),(at ?t i j-1)i
Delete Effects:
h(blank i j-1),(at ?t i j)i
Move tile ?t right from (i, j) ∈ {1 . . . N} × {1 . . . N-1}
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Move tile ?t up from (i, j) ∈ {2 . . . N} × {1 . . . N}
Move tile ?t down from (i, j) ∈ {1 . . . N-1} × {1 . . . N}
Move tile ?t left from (i, j) ∈ {1 . . . N} × {2 . . . N}
Move tile ?t right from (i, j) ∈ {1 . . . N} × {1 . . . N-1}
Move-Right(?t, i, j):
Preconditions:
h(blank i j+1),(at ?t i j)i
Add Effects:
h(blank i j),(at ?t i j+1)i
Delete Effects:
h(blank i j+1),(at ?t i j)i
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Initially we have
(at 1 1 1),(at 2 2 2),(at 3 3 2),(at 4 1 3),(at 5 2 1)
(blank 1 2),(blank 2 3),(blank 3 1),(blank 3 3)
Goal
STRIPS: Problem definition
Predicates
Operators
Initial State
In goal we demand
(at 1 1 1),(at 2 1 2),(at 3 1 3),(at 4 2 1),(at 5 2 2)
Real World Example III
Count Oldguy lives in a castle with two treasure rooms:
RoomA and RoomB. While RoomB is empty, RoomA contains
a pile of n different golden coins. Count Oldguy plans to have
a party in RoomA and therefore he has to move all the coins to
RoomB. The task is too hard for him to do it himself, and he
trusts no mortal, and hence he buys a robot Roby. Roby has
two arms, ArmA and ArmB, each can hold up to one coin.
Each arm can pick up and drop any coin and Roby can move
from RoomA to RoomB and vice versa. Initially, Roby is in
RoomA, and both its arms are empty.
STRIPS: Problem definition
Predicates
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
(at ?c ?r) — Coin c is in room r.
(carry ?a ?c) — Arm a carries coin c.
(at-robby ?r) — Robot is in room r.
(free ?a) — Arm a is free.
Operators
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up coin ?c with arm ?a in room ?r
Drop coin ?c from arm ?a in room ?r
Move robot from room ?x to room ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up coin ?c with arm ?a in room ?r
Pick(?c, ?a, ?r):
Preconditions:
h(at ?c ?r),(at-robby ?r),(free ?a)i
Add Effects:
h(carry ?a ?c)i
Delete Effects:
h(at ?c ?r),(free ?a)i
Drop coin ?c from arm ?a in room ?r
Move robot from room ?x to room ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up coin ?c with arm ?a in room ?r
Drop coin ?c from arm ?a in room ?r
Drop(?c, ?a, ?r):
Preconditions:
h(carry ?a ?c),(at-robby ?r)i
Add Effects:
h(at ?c ?r),(free ?a)i
Delete Effects:
h(carry ?a ?c)i
Move robot from room ?x to room ?y
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Pick up coin ?c with arm ?a in room ?r
Drop coin ?c from arm ?a in room ?r
Move robot from room ?x to room ?y
Move(?x, ?y):
Preconditions:
h(at-robby ?x)i
Add Effects:
h(at-robby ?y)i
Delete Effects:
h(at-robby ?x)i
Initial State
Goal
STRIPS: Problem definition
Predicates
Operators
Initially we have
(at c1 RoomA), . . . ,(at cn RoomA)
(at-robby RoomA)
(free ArmA),(free ArmB)
Goal
STRIPS: Problem definition
Predicates
Operators
Initial State
In goal we demand
(at c1 RoomB), . . . ,(at cn RoomB)"

4. "Principles of AI (Planning)
7. Relaxed Planning Graph
William Davidson Faculty of Industrial Engineering and Management
Technion - Israel Institute of Technology
Sliding Tile Puzzle 2X2
P =



11,1, 11,2, 12,1, 12,2,
21,1, 21,2, 22,1, 22,2,
31,1, 31,2, 32,1, 32,2,
b1,1, b1,2, b2,1, b2,2



O =



U(12,1),U(12,2),U(22,1),U(22,2),U(32,1),U(32,2),
D(11,1), D(11,2), D(21,1), D(21,2), D(31,1), D(31,2),
L(11,2), L(12,2), L(21,2), L(22,2), L(31,2), L(32,2),
R(11,1), R(12,1), R(21,1), R(22,1), R(31,1), R(32,1),



I = {31,1, 21,2, 12,2, b2,1}
G = {11,1, 21,2, 32,1}
Sliding Tile Puzzle: Operators
U(12,1) = h{b1,1, 12,1}, {b2,1, 11,1}, {b1,1, 12,1}i
U
+(12,1) = h{b1,1, 12,1}, {b2,1, 11,1}, ∅i
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
L+(12,2)
1
D+(31,1)
1
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
1
2
1,1
1
2
1,2
1
2
2,1
1
2
2,2
2
2
1,1
2
2
1,2
2
2
2,1
2
2
2,2
3
2
1,1
3
2
1,2
3
2
2,1
3
2
2,2
b
2
1,1
b
2
1,2
b
2
2,1
b
2
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
1
2
1,1
1
2
1,2
1
2
2,1
1
2
2,2
2
2
1,1
2
2
1,2
2
2
2,1
2
2
2,2
3
2
1,1
3
2
1,2
3
2
2,1
3
2
2,2
b
2
1,1
b
2
1,2
b
2
2,1
b
2
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
1
2
1,1
1
2
1,2
1
2
2,1
1
2
2,2
2
2
1,1
2
2
1,2
2
2
2,1
2
2
2,2
3
2
1,1
3
2
1,2
3
2
2,1
3
2
2,2
b
2
1,1
b
2
1,2
b
2
2,1
b
2
2,2
L+(12,2)
2
D+(31,1)
2
L+(21,2)
2
D+(21,2)
2
U+(32,1)
2
R+(32,1)
2
R+(12,1)
2
U+(12,1)
2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
L+(12,2)
2
D+(31,1)
2
L+(21,2)
2
D+(21,2)
2
U+(32,1)
2
R+(32,1)
2
R+(12,1)
2
U+(12,1)
2
1
2
1,1
1
2
1,2
1
2
2,1
1
2
2,2
2
2
1,1
2
2
1,2
2
2
2,1
2
2
2,2
3
2
1,1
3
2
1,2
3
2
2,1
3
2
2,2
b
2
1,1
b
2
1,2
b
2
2,1
b
2
2,2
Sliding Tile Puzzle: Relaxed Planning Graph
1
0
1,1
1
0
1,2
1
0
2,1
1
0
2,2
2
0
1,1
2
0
1,2
2
0
2,1
2
0
2,2
3
0
1,1
3
0
1,2
3
0
2,1
3
0
2,2
b
0
1,1
b
0
1,2
b
0
2,1
b
0
2,2
L+(12,2)
1
D+(31,1)
1
1
1
1,1
1
1
1,2
1
1
2,1
1
1
2,2
2
1
1,1
2
1
1,2
2
1
2,1
2
1
2,2
3
1
1,1
3
1
1,2
3
1
2,1
3
1
2,2
b
1
1,1
b
1
1,2
b
1
2,1
b
1
2,2
L+(12,2)
2
D+(31,1)
2
L+(21,2)
2
D+(21,2)
2
U+(32,1)
2
R+(32,1)
2
R+(12,1)
2
U+(12,1)
2
1
2
1,1
1
2
1,2
1
2
2,1
1
2
2,2
2
2
1,1
2
2
1,2
2
2
2,1
2
2
2,2
3
2
1,1
3
2
1,2
3
2
2,1
3
2
2,2
b
2
1,1
b
2
1,2
b
2
2,1
b
2
2,2
G
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
11
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
11
00001111
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
11
00001111
11222222
Sliding Tile Puzzle:
hmax
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
11
00001111
11222222
2102020121201
Sliding Tile Puzzle:
hmax = 2
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
a
2
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
G
0000
11
00001111
11222222
2102020121201
2"

5. "Principles of AI (Planning)
8. Heuristics on Relaxed Planning Graph
William Davidson Faculty of Industrial Engineering and Management
Technion - Israel Institute of Technology
Sliding Tile Puzzle 2X2
P =



11,1, 11,2, 12,1, 12,2,
21,1, 21,2, 22,1, 22,2,
31,1, 31,2, 32,1, 32,2,
b1,1, b1,2, b2,1, b2,2



O =



U(12,1),U(12,2),U(22,1),U(22,2),U(32,1),U(32,2),
D(11,1), D(11,2), D(21,1), D(21,2), D(31,1), D(31,2),
L(11,2), L(12,2), L(21,2), L(22,2), L(31,2), L(32,2),
R(11,1), R(12,1), R(21,1), R(22,1), R(31,1), R(32,1),



I = {31,1, 21,2, 12,2, b2,1}
G = {11,1, 21,2, 32,1}
Sliding Tile Puzzle: Operators
U(12,1) = h{b1,1, 12,1}, {b2,1, 11,1}, {b1,1, 12,1}i
U
+(12,1) = h{b1,1, 12,1}, {b2,1, 11,1}, ∅i
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
11
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
11
00001111
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
11
00001111
11223333
Sliding Tile Puzzle:
hadd
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
11
00001111
11223333
3102020131201
Sliding Tile Puzzle:
hadd = 4
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
0000
11
00001111
11223333
3102020131201
4
Sliding Tile Puzzle: h
F F — Justified Nodes
Justified Action Node
We say that an action node is justified if all its true immediate
predecessors are marked.
Justified Proposition Node
We say that a proposition node is justified if at least one of its
immediate predecessors is marked.
Sliding Tile Puzzle: h
F F — Marking Rules
Apply these rules until all marked nodes are justified
1 Mark all immediate predecessors of a marked unjustified
ACTION node.
2 Mark the immediate predecessor of a marked unjustified
PROP node with only one immediate predecessor.
3 Mark an immediate predecessor of a marked unjustified
PROP node connected via an idle arc.
4 Mark any immediate predecessor of a marked unjustified
PROP node.
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
G
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
M
M
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
M
M
MM
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
M
M
MM
M
MM
Sliding Tile Puzzle:
h
F F
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
M
M
MM
M
MM
MMM
Sliding Tile Puzzle:
h
F F = 3
a
0
b
0
c
0
d
0
e
0
f
0
g
0
h
0
i
0
j
0
k
0
l
0m0 n0o0p0
a
1
b
1
c
1
d
1
e
1
f
1
g
1
h
1
i
1
j
1
k
1
l
1m
1
n
1
o
1
p
1
a
1
a
2
a
2
b
2
c
2
d
2
e
2
f
2
g
2
h
2
i
2
j
2
k
2
l
2m2 n2o2p2
a
1
a
2
a
3
a
4
a
5
a
6
a
7
a
8
MG
MMM
M
M
MM
M
MM
MMM
M"

6. "AI – Tutorial 8
Propositional Logic
Resolution + DPLL
Slides adapted from Alex Tuisov and edited by Dvir Twito
Propositional Logic
 A system that is built based on logical expressions.
 Our focus: Zeroth-order logic.
 No Quantifiers.
Definitions
 Building blocks: Symbols.
 Can be True or False.
 p, q, r, …
 Symbols create literals.
 Positive literal is a symbol.
 p, q, r, …
 Negative literal is a negated symbol.
 ¬p, ¬q, ¬r, …
Definitions – Cont.
 Literals create clauses.
 Conjunction (and): p ⋀ q
 Disjunction (or): p ⋁ q
 Implication: p → q, q ← p
 If and only if (iff): p ↔ q
Definitions – Cont.
 Clauses create formula.
 (p ⋁ q) ↔ (¬q → r)
 (¬p → r) ↔ (¬r → p) ⋀ (q ⋁ r)
Horn Form
 Every clause contains one of:
 A single symbol.
 An implication of the form (conjunction of symbols) → symbol.
 No negations – only positive literals.
 Not every zeroth-order logic formula can be converted
into Horn form.
Modus Ponens
 Rule of inference.
 If we know that p → q, and that p is True, what can
we infer?
 We can infer q.
 Complete for Horn Form knowledge bases.
 Can be used to perform inference in linear time.
 Disadvantages?
 Not every logic formula can be converted into Horn
form.
CNF
 Conjunctive Normal Form.
 Every clause contains only “or” between literals.
 All clauses have “and” between them.
 Simply: “And between Ors”
 Examples:
 p ⋁ q
 p ⋀ q
 (p ⋁ q) ⋀ (¬q ⋁ r ⋁ ¬s) ⋀ (a)
CNF – Cont.
 Every zeroth-order logic formula can be converted
into CNF.
 The conversion is based on logical equivalences:
 Double negation elimination.
 ¬(¬p) ≡ p
 De Morgan's laws.
 ¬(p ⋁ q) ≡ ¬p ⋀ ¬q
 ¬(p ⋀ q) ≡ ¬p ⋁ ¬q
 Distributive law.
 p ⋁ (q ⋀ r) ≡ (p ⋁ q) ⋀ (p ⋁ r)
CNF – Cont.
 More logical equivalences:
 Implication.
 p → q ≡ ¬p ⋁ q
 If and only if.
 p ↔ q ≡ (p → q) ⋀ (q → p)
SAT
 Propositional satisfiability problem.
 Given a formula, can we find an assignment that
satisfies it?
 NP-Complete problem 😔.
 We are still trying to solve it as quickly as possible.
SAT – Cont.
 What is the naïve approach to solve the problem?
 Can we do better?
 If you can find an asymptotically better solution you can win
a one-million-dollar price!
(Just tell me before)
Resolution
 Rule of inference.
 In general:
 Given: (x ⋁ A) ⋀ (¬x ⋁ B)
 We can infer: A ⋁ B
 Problem: We had two small clauses, now we have one
big one (A, B could be big).
 Unit Resolution:
 Given: (x) Λ (¬x ⋁ B)
 We can infer: B.
Resolution
 Complete for CNF knowledge bases.
 Does it complete for every knowledge base?
Resolution – Example
 You are given the following knowledge base:
 KB = (¬p ⋁ q ⋁ r) ⋀ (p ⋁ r ⋁ s) ⋀ (¬p ⋁ ¬q).
 Can you prove/disprove the clause r ⋁ s ?
 I.e, does KB ⊨ (r ⋁ s) ?
 Davis–Putnam–Logemann–Loveland Algorithm.
 Helps solve SAT problem fast (on average).
 Uses two simple rules:
 Unit propagation:
 If a clause contains only a single unassigned literal, this
clause can only be satisfied by assigning the necessary
value to make this literal true.
 Pure literal elimination:
 If a symbol occurs with only one polarity in the formula, it
is called pure, and can always be assigned in a way that
makes all clauses containing it true.
DPLL Algorithm
function DPLL(Φ):
if Φ is a consistent set of literals then:
return true;
if Φ contains an empty clause then:
return false;
for every unit clause C in Φ do:
Φ = unit-propagate(C, Φ);
for every literal ltrl that occurs pure in Φ do:
Φ = pure-literal-assign(ltrl, Φ);
ltrl ≔ choose-literal(Φ);
return DPLL(Φ Λ not(ltrl)) or DPLL(Φ Λ ltrl);
DPLL – Pseudo Code
False (left)
True (right)
Branching
Pure symbol
Unit clause
DPLL – Legend
C1:(a ⋁ b)
C2:(¬a ⋁ ¬b)
C3:(a ⋁ ¬c)
C4:(c ⋁ d ⋁ e)
C5:(d ⋁ ¬e)
C6:(¬d ⋁ ¬f)
C7:(f ⋁ e)
C8:(¬f ⋁ ¬e)
a Pure Symbol ?
b Yes, No pure symbol b in C1 is pure
Unit Clause?
Yes C3 is an unit
clause
c
No unit clause
d
C4 is a unit clause
e
C5 is unsatisfied,
Early termination
Backtrack upto the
last branching:
d = false
DPLL – Example
Branching
Pure symbol
Unit clause
False (left)
True (right)
C1:(a ⋁ b)
C2:(¬a ⋁ ¬b)
C3:(a ⋁ ¬c)
C4:(c ⋁ d ⋁ e)
C5:(d ⋁ ¬e)
C6:(¬d ⋁ ¬f)
C7:(f ⋁ e)
C8:(¬f ⋁ ¬e)
a
b
c
d C6 is an unit
f
clause
e is pure
e
Formula
Satisfied!
DPLL – Example
Branching
Pure symbol
Unit clause
False (left)
True (right)
 Find a satisfying assignment (if one exists) using
DPLL.
 (¬a ⋁ b)
 (¬a ⋁ ¬b ⋁ c)
 (¬c ⋁ d ⋁ ¬e)
 (a ⋁ c)
 (¬d ⋁ ¬f)
 (a ⋁ c)
 (e ⋁ ¬f)
DPLL – Exercise
 Next week we will learn how to represent a
deterministic planning problem as a logical formula.
 Once we do it, we can use DPLL in order to solve a
(SAT planning).
"

7. "Planning as
SAT
Linear
Encoding
Parallel
Encoding
Introduction to AI
Planning via SAT: Encodings
William Davidson Faculty of Industrial Engineering and Management
Technion - Israel Institute of Technology
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Outline 1 Planning as SAT 2 Linear Encoding
Notation
Encoding
Example
3 Parallel Encoding
Notation
Encoding
Example
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Example Task
Logistics Task with
truck: T
package: A
locations: L,R
Atoms: P = {AL, AR, AT, TL, TR}
Actions: A = {DRL, DLR, LR, LL, UR, UL}
LL = h{AL, TL}, {AT}, {AL}i
UL = h{TL, AT}, {AL}, {AT}i
DLR = h{TL}, {TR}, {TL}i
Initial state: I = {AL, TL}
Goal: G = {AR}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Outline 1 Planning as SAT 2 Linear Encoding
Notation
Encoding
Example
3 Parallel Encoding
Notation
Encoding
Example
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Notation
Input
Planning task Π = hP, A, I, Gi
Bound b and time steps 0 ≤ t ≤ b
Decision variables
pt — for all p ∈ P, 0 ≤ t ≤ b
at — for all a ∈ AN , 0 ≤ t ≤ b − 1
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Basic Linear Encoding (1)
Initial State Clauses
Specify initial state
for all p ∈ P : {p0} if p ∈ I, and {¬p0}, otherwise
Goal Clauses
Specify goal values
for all p ∈ G : {pb}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Basic Linear Encoding (2)
Action Precondition Clauses
Action implies its preconditions
for all a ∈ A, p ∈ pre(a), 0 ≤ t ≤ b − 1 : {¬at
, pt}
Action Effect Clauses
Action implies its add/delete effects
for all a ∈ A, p ∈ add(a), 0 ≤ t ≤ b − 1 : {¬at
, pt+1}
for all a ∈ A, p ∈ del(a), 0 ≤ t ≤ b − 1 : {¬at
, ¬pt+1}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Basic Linear Encoding (3)
Positive Frame Axioms
If a is applied, and p 6∈ del(a) was true, then p is still true
for all a ∈ A, p 6∈ del(a), 0 ≤ t ≤ b − 1 : {¬at
, ¬pt
, pt+1}
Negative Frame Axioms
If a is applied, and p 6∈ add(a) was false, then p is still false
for all a ∈ A, p 6∈ add(a), 0 ≤ t ≤ b − 1 : {¬at
, pt
, ¬pt+1}
Linearity (exclusion) Constraints
Apply exactly one action at each time step
for all a, a0 ∈ A, 0 ≤ t ≤ b − 1 : {¬at
, ¬a
0
t}
for all 0 ≤ t ≤ b − 1 : {a
1
t
, a2
t
, . . .}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Initial State (b=1)
Initial State Clauses
for all p ∈ P : {p0} if p ∈ I, and {¬p0}, otherwise
Initial State - Example Task
Initial state: I = {AL, TL}
P = {AL, AR, AT, TL, TR}
Initial State Clauses - Example Task
{AL0}, {¬AR0}, {¬AT0}, {TL0}, {¬TR0}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Goal (b=1)
Goal Clauses
for all p ∈ G : {pb}
Goal - Example Task
G = {AR}
Goal Clauses - Example Task
{AR1}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Action Precondition (b=1)
Action Precondition Clauses
for all a ∈ A, p ∈ pre(a), 0 ≤ t ≤ b − 1 : {¬at
, pt}
Action Preconditions - Example Task
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Action Precondition Clauses - Example Task
{¬LR0, AR0}, {¬LR0, TR0}, {¬LL0, AL0}, {¬LL0, TL0},
{¬UR0, AT0}, {¬UR0, TR0}, {¬UL0, AT0}, {¬UL0, TL0},
{¬DRL0, TR0}, {¬DLR0, TL0},
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Action Effects (b=1)
Action Effect Clauses
for all a ∈ A, p ∈ add(a), 0 ≤ t ≤ b − 1 : {¬at
, pt+1}
for all a ∈ A, p ∈ del(a), 0 ≤ t ≤ b − 1 : {¬at
, ¬pt+1}
Action Effects - Example Task
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Action Effect Clauses - Example Task
{¬LR0, AT1}, {¬LR0, ¬AR1}, {¬LL0, AT1}, {¬LL0, ¬AL1},
{¬UR0, AR1}, {¬UR0, ¬AT1}, {¬UL0, AL1}, {¬UL0, ¬AT1},
{¬DRL0, TL1}, {¬DRL0, ¬TR1}, {¬DLR0, TR1},
{¬DLR0, ¬TL1}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Positive Frame Axioms (b=1)
Positive Frame Axiom Clauses
for all a ∈ A, p 6∈ del(a), 0 ≤ t ≤ b − 1 : {¬at
, ¬pt
, pt+1}
Positive Frame Axioms - Example Task
P = {AL, AR, AT, TL, TR}
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Positive Frame Axiom Clauses - Example Task
{¬LL0, ¬AR0, AR1}, {¬LL0, ¬AT0, AT1}, {¬LL0, ¬TL0, TL1},
{¬LL0, ¬TR0, TR1}, {¬LR0, ¬AL0, AL1}, {¬LR0, ¬AT0, AT1},
{¬LR0, ¬TL0, TL1}, {¬LR0, ¬TR0, TR1}, {¬UL0, ¬AR0, AR1},
{¬UL0, ¬AL0, AL1}, {¬UL0, ¬TL0, TL1}, {¬UL0, ¬TR0, TR1},
{¬UR0, ¬AR0, AR1}, {¬UR0, ¬AL0, AL1}, {¬UR0, ¬TL0, TL1},
{¬UR0, ¬TR0, TR1}, {¬DLR0, ¬AR0, AR1}, {¬DLR0, ¬AL0, AL1},
{¬DLR0, ¬AT0, AT1}, {¬DLR0, ¬TR0, TR1}, {¬DRL0, ¬AR0, AR1},
{¬DRL0, ¬AL0, AL1}, {¬DRL0, ¬AT0, AT1}, {¬DRL0, ¬TR0, TL1}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Negative Frame Axioms (b=1)
Negative Frame Axiom Clauses
for all a ∈ A, p 6∈ add(a), 0 ≤ t ≤ b − 1 : {¬at
, pt
, ¬pt+1}
Negative Frame Axioms - Example Task
P = {AL, AR, AT, TL, TR}
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Negative Frame Axiom Clauses - Example Task
{¬LL0, AR0, ¬AR1}, {¬LL0, AL0, ¬AL1}, {¬LL0, TL0, ¬TL1},
{¬LL0, TR0, ¬TR1}, {¬LR0, AL0, ¬AL1}, {¬LR0, AR0, ¬AR1},
{¬LR0, TL0, ¬TL1}, {¬LR0, TR0, ¬TR1}, {¬UL0, AR0, ¬AR1},
{¬UL0, AT0, ¬AT1}, {¬UL0, TL0, ¬TL1}, {¬UL0, TR0, ¬TR1},
{¬UR0, AL0, ¬AL1}, {¬UR0, AT0, ¬AT1}, {¬UR0, TL0, ¬TL1},
{¬UR0, TR0, ¬TR1}, {¬DLR0, AR0, ¬AR1}, {¬DLR0, AL0, ¬AL1},
{¬DLR0, AT0, ¬AT1}, {¬DLR0, TL0, ¬TL1}, {¬DRL0, AR0, ¬AR1},
{¬DRL0, AL0, ¬AL1}, {¬DRL0, AT0, ¬AT1}, {¬DRL0, TR0, ¬TR1}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Linearity Constraints (b=1)
Linearity (exclusion) Constraint Clauses
for all a, a0 ∈ A, 0 ≤ t ≤ b − 1 : {¬at
, ¬a
0
t}
for all 0 ≤ t ≤ b − 1 : {a
1
t
, a2
t
, . . .}
Linearity (exclusion) Constraints - Example Task
A = {LL, LR, UL, UR, DLR, DRL}
Linearity (exclusion) Constraint Clauses - Example Task
{¬LL0, ¬LR0}, {¬LL0, ¬UL0}, {¬LL0, ¬UR0}, {¬LL0, ¬DLR0},
{¬LL0, ¬DRL0}, {¬LR0 ¬UL0}, {¬LR0 ¬UR0}, {¬LR0 ¬DLR0},
{¬LR0 ¬DRL0}, {¬UL0 ¬UR0}, {¬UL0 ¬DLR0}, {¬UL0 ¬DRL0},
{¬UR0 ¬DLR0}, {¬UR0 ¬DRL0}, {¬DLR0 ¬DRL0}
{LL0, LR0, UL0, UR0, DLR0, DRL0}
Planning as
SAT
Linear
Encoding
Notation
Encoding
Example
Parallel
Encoding
Linear Encoding - Example Task (b=1)
{AL0}, {¬AR0}, {¬AT0}, {TL0}, {¬TR0}
{AR1}
{¬LR0, AR0}, {¬LR0, TR0}, {¬LL0, AL0}, {¬LL0, TL0}, {¬UR0, AT0},
{¬UR0, TR0}, {¬UL0, AT0}, {¬UL0, TL0}, {¬DRL0, TR0}, {¬DLR0, TL0},
{¬LR0, AT1}, {¬LR0, ¬AR1}, {¬LL0, AT1}, {¬LL0, ¬AL1}, {¬UR0, AR1},
{¬UR0, ¬AT1}, {¬UL0, AL1}, {¬UL0, ¬AT1}, {¬DRL0, TL1}, {¬DRL0, ¬TR1},
{¬DLR0, TR1}, {¬DLR0, ¬TL1}
{¬LL0, ¬AR0, AR1}, {¬LL0, ¬AT0, AT1}, {¬LL0, ¬TL0, TL1},
{¬LL0, ¬TR0, TR1}, {¬LR0, ¬AL0, AL1}, {¬LR0, ¬AT0, AT1},
{¬LR0, ¬TL0, TL1}, {¬LR0, ¬TR0, TR1}, {¬UL0, ¬AR0, AR1},
{¬UL0, ¬AL0, AL1}, {¬UL0, ¬TL0, TL1}, {¬UL0, ¬TR0, TR1},
{¬UR0, ¬AR0, AR1}, {¬UR0, ¬AL0, AL1}, {¬UR0, ¬TL0, TL1},
{¬UR0, ¬TR0, TR1}, {¬DLR0, ¬AR0, AR1}, {¬DLR0, ¬AL0, AL1},
{¬DLR0, ¬AT0, AT1}, {¬DLR0, ¬TR0, TR1}, {¬DRL0, ¬AR0, AR1},
{¬DRL0, ¬AL0, AL1}, {¬DRL0, ¬AT0, AT1}, {¬DRL0, ¬TR0, TL1}
{¬LL0, AR0, ¬AR1}, {¬LL0, AL0, ¬AL1}, {¬LL0, TL0, ¬TL1},
{¬LL0, TR0, ¬TR1}, {¬LR0, AL0, ¬AL1}, {¬LR0, AR0, ¬AR1},
{¬LR0, TL0, ¬TL1}, {¬LR0, TR0, ¬TR1}, {¬UL0, AR0, ¬AR1},
{¬UL0, AT0, ¬AT1}, {¬UL0, TL0, ¬TL1}, {¬UL0, TR0, ¬TR1},
{¬UR0, AL0, ¬AL1}, {¬UR0, AT0, ¬AT1}, {¬UR0, TL0, ¬TL1},
{¬UR0, TR0, ¬TR1}, {¬DLR0, AR0, ¬AR1}, {¬DLR0, AL0, ¬AL1},
{¬DLR0, AT0, ¬AT1}, {¬DLR0, TL0, ¬TL1}, {¬DRL0, AR0, ¬AR1},
{¬DRL0, AL0, ¬AL1}, {¬DRL0, AT0, ¬AT1}, {¬DRL0, TR0, ¬TR1}
{¬LL0, ¬LR0}, {¬LL0, ¬UL0}, {¬LL0, ¬UR0}, {¬LL0, ¬DLR0},
{¬LL0, ¬DRL0}, {¬LR0 ¬UL0}, {¬LR0 ¬UR0}, {¬LR0 ¬DLR0},
{¬LR0 ¬DRL0}, {¬UL0 ¬UR0}, {¬UL0 ¬DLR0}, {¬UL0 ¬DRL0},
{¬UR0 ¬DLR0}, {¬UR0 ¬DRL0}, {¬DLR0 ¬DRL0}
{LL0, LR0, UL0, UR0, DLR0, DRL0}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Outline 1 Planning as SAT 2 Linear Encoding
Notation
Encoding
Example
3 Parallel Encoding
Notation
Encoding
Example
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Notation
Input
Planning task Π = hP, A, I, Gi
Noop extended actions set AN (Noop(p) = h{p}, {p}, {}i)
Bound b and time steps 0 ≤ t ≤ b
a | a
0 denote that a and a’ are non-interfering
Decision variables
pt — for all p ∈ P, 0 ≤ t ≤ b
at — for all a ∈ AN , 0 ≤ t ≤ b − 1
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Interfering Actions
A pair of Strips actions a1 6= a2 interfere if
del(a1) ∩ (pre(a2) ∪ add(a2)) 6= ∅, or
del(a2) ∩ (pre(a1) ∪ add(a1)) 6= ∅.
Some interfering actions:
DLR and LL: TL ∈ del(DLR) ∩ pre(LL)
UL and LL: AT ∈ del(UL) ∩ add(LL)
Some non-interfering actions:
DLR and LR
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Example Task with NOOPS
Logistics Task with NOOPS
truck: T
package: A
locations: L,R
Atoms: P = {AL, AR, AT, TL, TR}
Actions: AN = {DRL, DLR, LR, LL, UR, UL,
Noop(AL), Noop(AR), Noop(AT),
Noop(TL), Noop(TR)}
LL = h{AL, TL}, {AT}, {AL}i
UL = h{TL, AT}, {AL}, {AT}i
DLR = h{TL}, {TR}, {TL}i
Noop(AL) = h{AL}, {AL}, {}i
Initial state: I = {AL, TL}
Goal: G = {AR}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Basic Parallel Encoding (1)
Initial State Clauses
Specify initial state
for all p ∈ P : {p0} if p ∈ I, and {¬p0}, otherwise
Goal Clauses
Specify goal values
for all p ∈ G : {pb}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Basic Parallel Encoding (2)
Action Precondition Clauses
Action implies its preconditions
for all a ∈ AN , p ∈ pre(a), 0 ≤ t ≤ b − 1 : {¬at
, pt}
Action Interference Clauses
Do not apply interfering actions at the same time step
for all a, a0 ∈ AN , a 6 | a
0
, 0 ≤ t ≤ b − 1 : {¬at
, ¬a
0
t}
Fact Achievement Clauses
Fact implies disjunction of its achievers
for all p ∈ P, 1 ≤ t ≤ b : {¬pt} ∪ {at−1 | p ∈ add(a)}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Parallel Encoding - Initial State (b=1)
Initial State Clauses
for all p ∈ P : {p0} if p ∈ I, and {¬p0}, otherwise
Initial State - Example Task
Initial state: I = {AL, TL}
P = {AL, AR, AT, TL, TR}
Initial State Clauses - Example Task
{AL0}, {¬AR0}, {¬AT0}, {TL0}, {¬TR0}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Parallel Encoding - Goal (b=1)
Goal Clauses
for all p ∈ G : {pb}
Goal - Example Task
G = {AR}
Goal Clauses - Example Task
{AR1}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Parallel Encoding - Action Precondition (b=1)
Action Precondition Clauses
for all a ∈ AN , p ∈ pre(a), 0 ≤ t ≤ b − 1 : {¬at
, pt}
Action Preconditions - Example Task
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Noop(AL) = h{AL}, {AL}, {}i
Action Precondition Clauses - Example Task
{¬LR0, AR0}, {¬LR0, TR0}, {¬LL0, AL0}, {¬LL0, TL0},
{¬UR0, AT0}, {¬UR0, TR0}, {¬UL0, AT0}, {¬UL0, TL0},
{¬DRL0, TR0}, {¬DLR0, TL0}, {¬Noop(AL)0, AL0},
{¬Noop(AR)0, AR0}, {¬Noop(AT)0, AT0}, {¬Noop(TL)0, TL0},
{¬Noop(TR)0, TR0}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Parallel Encoding - Action Interference (b=1)
Action Interference Clauses
for all a, a0 ∈ AN , a 6 | a
0
, 0 ≤ t ≤ b − 1 : {¬at
, ¬a
0
t}
Action Interference - Example Task
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
Noop(AL) = h{AL}, {AL}, {}i
Action Interference Clauses - Example Task
{¬DLR0, ¬DRL0}, {¬DLR0, ¬LL0}, {¬DLR0, ¬UL0},
{¬DLR0, ¬Noop(TL)0}, {¬DRL0, ¬LR0}, {¬DRL0, ¬UR0},
{¬DRL0, ¬Noop(TR)0}, {¬LL0, ¬UL0}, {¬LL0, ¬UR0},
{¬LL0, ¬Noop(AL)0}, {¬LR0, ¬UL0}, {¬LR0, ¬UR0},
{¬LR0, ¬Noop(AR)0}, {¬UL0, ¬UR0}, {¬UL0, ¬Noop(AT)0},
{¬UR0, ¬Noop(AT)0}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Parallel Encoding - Fact Achievement (b=1)
Fact Achievement Clauses
for all p ∈ P, 1 ≤ t ≤ b : {¬pt} ∪ {at−1 | p ∈ add(a)}
Fact Achievement - Example Task
DLR = h{TL}, {TR}, {TL}i, DRL = h{TR}, {TL}, {TR}i
LL = h{AL, TL}, {AT}, {AL}i, LR = h{AR, TR}, {AT}, {AR}i
UL = h{TL, AT}, {AL}, {AT}i, UR = h{TR, AT}, {AR}, {AT}i
Noop(AL) = h{AL}, {AL}, {}i
Fact Achievement - Example Task
{¬AL1, UL0, Noop(AL)0}, {¬AR1, UR0, Noop(AR)0},
{¬AT1, LL0, LR0, Noop(AT)0}, {¬TL1, DRL0, Noop(TL)0},
{¬TR1, DLR0, Noop(TR)0}
Planning as
SAT
Linear
Encoding
Parallel
Encoding
Notation
Encoding
Example
Example Task - Basic Parallel Encoding (b=1)
{AL0}, {¬AR0}, {¬AT0}, {TL0}, {¬TR0}
{AR1}
{¬LR0, AR0}, {¬LR0, TR0}, {¬LL0, AL0}, {¬LL0, TL0},
{¬UR0, AT0}, {¬UR0, TR0}, {¬UL0, AT0}, {¬UL0, TL0},
{¬DRL0, TR0}, {¬DLR0, TL0}, {¬Noop(AL)0, AL0},
{¬Noop(AR)0, AR0}, {¬Noop(AT)0, AT0}, {¬Noop(TL)0, TL0},
{¬Noop(TR)0, TR0}
{¬DLR0, ¬DRL0}, {¬DLR0, ¬LL0}, {¬DLR0, ¬UL0},
{¬DLR0, ¬Noop(TL)0}, {¬DRL0, ¬LR0}, {¬DRL0, ¬UR0},
{¬DRL0, ¬Noop(TR)0}, {¬LL0, ¬UL0}, {¬LL0, ¬UR0},
{¬LL0, ¬Noop(AL)0}, {¬LR0, ¬UL0}, {¬LR0, ¬UR0},
{¬LR0, ¬Noop(AR)0}, {¬UL0, ¬UR0}, {¬UL0, ¬Noop(AT)0},
{¬UR0, ¬Noop(AT)0}
{¬AL1, UL0, Noop(AL)0}, {¬AR1, UR0, Noop(AR)0},
{¬AT1, LL0, LR0, Noop(AT)0}, {¬TL1, DRL0, Noop(TL)0},
{¬TR1, DLR0, Noop(TR)0}"

is the modeling in my code enough? is it possible to add more variables to the modeling of the problem, to further improve the modeling of the problem, and to do logical inference more easily when choosing the right actions:

###***######***######***######***###

# ex2.py

ids = ['123456789']  # Replace with your ID(s)

import math
from collections import deque
from utils import Expr, Symbol  # Import Expr and Symbol for logical expressions

class GringottsController:
    def __init__(self, map_shape, harry_loc, initial_observations):
        """
        Controller initialization.
        """
        self.rows, self.cols = map_shape
        self.harry_loc = harry_loc
        self.turn_count = 0

        # Initialize beliefs with uppercase symbols
        self.Trap_beliefs = [[None for _ in range(self.cols)] for _ in range(self.rows)]
        self.Dragon_beliefs = [[None for _ in range(self.cols)] for _ in range(self.rows)]
        self.Vault_beliefs = [[None for _ in range(self.cols)] for _ in range(self.rows)]

        # Mark starting cell as definitely not a Trap and not a Dragon
        r0, c0 = harry_loc
        self.Trap_beliefs[r0][c0] = False
        self.Dragon_beliefs[r0][c0] = False

        # Keep track of vaults already "collected" but discovered to be wrong
        self.collected_wrong_vaults = set()

        # Store constraints
        self.obs_constraints = []

        # Incorporate any initial observations
        self.update_with_observations(initial_observations)

        # Queue of planned actions
        self.current_plan = deque()

        # Memory of visited cells
        self.visited = set()
        self.visited.add(harry_loc)  # Add starting location

    def get_next_action(self, observations):
        """
        Decide on the next action with uppercase symbols.
        """
        self.turn_count += 1

        # 1) Update knowledge base with new constraints
        self.update_with_observations(observations)

        # 2) Solve the knowledge base for the most up-to-date assignment
        self.run_inference()

        # Debug: Print current beliefs
        print(f"Turn {self.turn_count}: Current Vault Beliefs: {self.Vault_beliefs}")
        print(f"Turn {self.turn_count}: Current Trap Beliefs: {self.Trap_beliefs}")
        print(f"Turn {self.turn_count}: Current Dragon Beliefs: {self.Dragon_beliefs}")

        # 3) Identify all definite Vaults
        definite_vaults = []
        for r in range(self.rows):
            for c in range(self.cols):
                if self.Vault_beliefs[r][c] is True:
                    definite_vaults.append((r, c))

        # 4) If we are on a Vault, try to collect it
        if (self.harry_loc in definite_vaults) and (self.harry_loc not in self.collected_wrong_vaults):
            action = ("collect",)
            print(f"Turn {self.turn_count}: Action selected: {action}")
            return action

        # 5) If any definite Vault exists and we are not on it, re-plan path to it
        if definite_vaults:
            # For simplicity, choose the first definite Vault found
            target_vault = definite_vaults[0]

            # Plan a path to the target Vault
            path = self.bfs_path(self.harry_loc, target_vault)

            if path and path != [self.harry_loc]:
                # Convert the path to a series of "move" actions
                moves = []
                current = self.harry_loc
                for step in path:
                    if step != current:
                        moves.append(("move", step))
                        current = step
                self.current_plan = deque(moves)

        # 6) If there's a known Trap adjacent, let's destroy it
        destroy_target = self.find_adjacent_definite_trap()
        if destroy_target:
            action = ("destroy", destroy_target)
            print(f"Turn {self.turn_count}: Action selected: {action}")
            return action

        # 7) If there's a planned action from previous turns, execute it
        if self.current_plan:
            action = self.current_plan.popleft()
            print(f"Turn {self.turn_count}: Action selected: {action}")
            # Update Harry's location if the action is a move
            if action[0] == "move":
                self.harry_loc = action[1]
                self.visited.add(action[1])  # Mark the new cell as visited
            return action

        # 8) Plan a path to a goal (Vault or safe cell)
        path = self.plan_path_to_goal()
        if not path:
            # If no path found, perform a "wait" as a fallback
            action = ("wait",)
            print(f"Turn {self.turn_count}: Action selected: {action}")
            return action

        # Check if the path leads to the current location (implies we are on a goal)
        if path[-1] == self.harry_loc:
            # We are already at the goal, perform "collect" if possible
            if self.Vault_beliefs[r][c] is True:
                action = ("collect",)
                print(f"Turn {self.turn_count}: Action selected: {action}")
                return action

        # Convert the path to a series of "move" actions
        moves = []
        current = self.harry_loc
        for step in path:
            if step != current:
                moves.append(("move", step))
                # Simulate Harry's movement in planning to prevent redundant moves
                current = step
        self.current_plan = deque(moves)

        # Return the next action from the plan
        if self.current_plan:
            action = self.current_plan.popleft()
            print(f"Turn {self.turn_count}: Action selected: {action}")
            # Update Harry's location if the action is a move
            if action[0] == "move":
                self.harry_loc = action[1]
                self.visited.add(action[1])  # Mark the new cell as visited
            return action
        else:
            action = ("wait",)
            print(f"Turn {self.turn_count}: Action selected: {action}")
            return action

    # -------------------------------------------------------------------------
    # Observation-based constraints
    # -------------------------------------------------------------------------

    def update_with_observations(self, obs_list):
        """
        Update beliefs based on observations using uppercase symbols.
        """
        # Mark Vault/Dragon if observed
        sulfur_detected = False
        for obs in obs_list:
            if obs[0] == "vault":
                (vr, vc) = obs[1]
                self.Vault_beliefs[vr][vc] = True
                self.Dragon_beliefs[vr][vc] = False
            elif obs[0] == "dragon":
                (dr, dc) = obs[1]
                self.Dragon_beliefs[dr][dc] = True
                self.Vault_beliefs[dr][dc] = False
            elif obs[0] == "sulfur":
                sulfur_detected = True
            elif obs[0] == "trap":
                (tr, tc) = obs[1]
                self.Trap_beliefs[tr][tc] = True

        # Update sulfur constraints
        self.remove_old_sulfur_constraint_for_cell(self.harry_loc)
        if sulfur_detected:
            # sum of Trap among neighbors >= 1
            self.obs_constraints.append(("SULFUR+", self.harry_loc))
        else:
            # sum of Trap among neighbors == 0
            self.obs_constraints.append(("SULFUR0", self.harry_loc))

    def remove_old_sulfur_constraint_for_cell(self, cell):
        """Keep only the most recent sulfur constraint for a cell."""
        newlist = []
        for c in self.obs_constraints:
            ctype, ccell = c
            if ccell != cell:
                newlist.append(c)
        self.obs_constraints = newlist

    # -------------------------------------------------------------------------
    # Logic solver: Backtracking with constraints
    # -------------------------------------------------------------------------

    def run_inference(self):
        """
        Perform backtracking to infer definite truths about the grid.
        """
        # 1) Gather all cells that remain None for Trap or Dragon or Vault
        partial_solution = self._snapshot_current_beliefs()
        cells_to_assign = []
        for r in range(self.rows):
            for c in range(self.cols):
                # Trap
                if self.Trap_beliefs[r][c] is None:
                    cells_to_assign.append(("Trap", r, c))
                # Dragon
                if self.Dragon_beliefs[r][c] is None:
                    cells_to_assign.append(("Dragon", r, c))
                # Vault
                if self.Vault_beliefs[r][c] is None:
                    cells_to_assign.append(("Vault", r, c))

        solutions = []
        max_solutions = 100  # Limit to prevent excessive computation
        self.dpll_backtrack(partial_solution, cells_to_assign, 0, solutions, max_solutions)

        if not solutions:
            # Contradictory observations
            return

        # Compute "forced" booleans = same value in all solutions
        merged = {}
        for var in solutions[0]:
            merged[var] = solutions[0][var]
        for sol in solutions[1:]:
            for var in sol:
                if merged[var] != sol[var]:
                    merged[var] = "UNSURE"

        # Store the definite beliefs
        for (kind, r, c), val in merged.items():
            if val == "UNSURE":
                pass  # remain None
            else:
                # True or False
                if kind == "Trap":
                    self.Trap_beliefs[r][c] = val
                elif kind == "Dragon":
                    self.Dragon_beliefs[r][c] = val
                elif kind == "Vault":
                    self.Vault_beliefs[r][c] = val

    def dpll_backtrack(self, partial_sol, vars_list, index, solutions, max_solutions):
        """
        Depth-first backtracking search to find all consistent assignments.
        Stops after finding max_solutions.
        """
        if len(solutions) >= max_solutions:
            return  # Reached maximum number of solutions

        if index >= len(vars_list):
            # All variables assigned
            solutions.append(dict(partial_sol))
            return

        varinfo = vars_list[index]
        # varinfo = ("Trap"/"Dragon"/"Vault", r, c)
        # If partial_sol already has a value, skip
        if partial_sol[varinfo] is not None:
            if self.check_constraints(partial_sol):
                self.dpll_backtrack(partial_sol, vars_list, index + 1, solutions, max_solutions)
            return
        else:
            for attempt in [False, True]:
                partial_sol[varinfo] = attempt
                if self.check_constraints(partial_sol):
                    self.dpll_backtrack(partial_sol, vars_list, index + 1, solutions, max_solutions)
                if len(solutions) >= max_solutions:
                    return  # Early exit if limit reached
            partial_sol[varinfo] = None  # Reset

    def check_constraints(self, partial_sol):
        """Check if the current partial assignment satisfies all constraints."""
        # 1) Not both Dragon & Vault in the same cell
        for r in range(self.rows):
            for c in range(self.cols):
                dval = partial_sol.get(("Dragon", r, c), None)
                vval = partial_sol.get(("Vault", r, c), None)
                if dval is True and vval is True:
                    return False  # Conflict

        # 2) SULFUR constraints
        for (ctype, cell) in self.obs_constraints:
            (rr, cc) = cell
            neighbors = self.get_4_neighbors(rr, cc)
            trap_sum = 0
            unknown_count = 0
            for (nr, nc) in neighbors:
                tval = partial_sol.get(("Trap", nr, nc), None)
                if tval is True:
                    trap_sum += 1
                elif tval is None:
                    unknown_count += 1

            if ctype == "SULFUR+":
                # At least one Trap
                if trap_sum == 0 and unknown_count == 0:
                    return False
            elif ctype == "SULFUR0":
                # No Traps
                if trap_sum > 0:
                    return False

        # 3) Exactly one Vault exists
        vault_count = 0
        for r in range(self.rows):
            for c in range(self.cols):
                vval = partial_sol.get(("Vault", r, c), None)
                if vval is True:
                    vault_count += 1
                elif vval is None:
                    pass  # Potential Vault

        if vault_count > 1:
            return False  # More than one Vault is invalid

        # Additionally, if all cells are assigned and no Vault is present, invalidate
        if vault_count == 0:
            all_assigned = True
            for r in range(self.rows):
                for c in range(self.cols):
                    if self.Vault_beliefs[r][c] is None:
                        all_assigned = False
                        break
            if all_assigned:
                return False  # At least one Vault must exist

        return True

    def _snapshot_current_beliefs(self):
        """
        Create a snapshot of current beliefs for backtracking.
        """
        d = {}
        for r in range(self.rows):
            for c in range(self.cols):
                d[("Trap", r, c)] = self.Trap_beliefs[r][c]
                d[("Dragon", r, c)] = self.Dragon_beliefs[r][c]
                d[("Vault", r, c)] = self.Vault_beliefs[r][c]
        return d

    # -------------------------------------------------------------------------
    # Action selection logic
    # -------------------------------------------------------------------------

    def find_adjacent_definite_trap(self):
        """Return the location of an adjacent Trap if known."""
        (r, c) = self.harry_loc
        for (nr, nc) in self.get_4_neighbors(r, c):
            tval = self.Trap_beliefs[nr][nc]
            if tval is True:
                return (nr, nc)
        return None

    def calculate_vault_probabilities(self):
        """
        Calculate the probability of each cell containing a vault.
        """
        probabilities = [[0.1 for _ in range(self.cols)] for _ in range(self.rows)]  # Default probability for unknown cells

        for r in range(self.rows):
            for c in range(self.cols):
                if self.Vault_beliefs[r][c] is True:
                    probabilities[r][c] = 1.0
                elif self.Vault_beliefs[r][c] is False:
                    probabilities[r][c] = 0.0
                else:
                    # Adjust probability based on whether the cell has been visited
                    if (r, c) not in self.visited:
                        probabilities[r][c] += 0.1  # Slightly higher probability for unvisited cells
                    # You can further adjust this based on other factors if desired

        return probabilities

    def plan_path_to_goal(self):
        """
        Plan a path to a Vault or a safe cell based on vault probabilities and visited cells.
        """
        # 1. Calculate vault probabilities
        vault_probs = self.calculate_vault_probabilities()

        # 2. Identify candidate goals with their probabilities
        goals = []
        for r in range(self.rows):
            for c in range(self.cols):
                if self.Vault_beliefs[r][c] is True:
                    if (r, c) not in self.collected_wrong_vaults:
                        goals.append(((r, c), 1.0))  # Definite vaults have probability 1
                elif self.Vault_beliefs[r][c] is None:
                    # Prefer unvisited cells by slightly increasing their probability
                    prob = vault_probs[r][c]
                    if (r, c) not in self.visited:
                        prob += 0.1  # Boost probability for unvisited cells
                    goals.append(((r, c), prob))  # Unknown cells have low probability

        # 3. Sort goals by probability in descending order
        goals.sort(key=lambda x: x[1], reverse=True)

        # 4. If no Vaults known, explore safe cells with higher probability
        if not goals:
            for r in range(self.rows):
                for c in range(self.cols):
                    if self.Trap_beliefs[r][c] is False and self.Dragon_beliefs[r][c] is False:
                        # Prefer unvisited cells by assigning higher probabilities
                        if (r, c) not in self.visited:
                            prob = 0.2  # Higher probability for unvisited safe cells
                        else:
                            prob = 0.1  # Lower probability for visited safe cells
                        goals.append(((r, c), prob))

        # 5. If still no goals, return None
        if not goals:
            return None

        # 6. Select the goal with the highest probability
        best_goal, best_prob = goals[0]

        # 7. Plan a path to the best goal using BFS
        return self.bfs_path(self.harry_loc, best_goal)

    def bfs_path(self, start, goal):
        """
        Perform BFS to find a path from start to goal, avoiding known Traps and Dragons.
        """
        if start == goal:
            return [start]
        from collections import deque
        visited = set()
        queue = deque()
        queue.append((start, [start]))
        visited.add(start)

        while queue:
            (cur, path) = queue.popleft()
            for nbd in self.get_4_neighbors(cur[0], cur[1]):
                nr, nc = nbd
                # Skip if Trap or Dragon is definitely present
                if self.Trap_beliefs[nr][nc] is True:
                    continue
                if self.Dragon_beliefs[nr][nc] is True:
                    continue
                if nbd not in visited:
                    visited.add(nbd)
                    newp = path + [nbd]
                    if nbd == goal:
                        return newp
                    queue.append((nbd, newp))
        return None

    def get_4_neighbors(self, r, c):
        """Return up/down/left/right neighbors within grid boundaries."""
        result = []
        if r > 0:
            result.append((r - 1, c))
        if r < self.rows - 1:
            result.append((r + 1, c))
        if c > 0:
            result.append((r, c - 1))
        if c < self.cols - 1:
            result.append((r, c + 1))
        return result

    def __repr__(self):
        return "<GringottsController using enhanced heuristics for inference and action selection>"

###***######***######***######***###

What I need from you now:
1. is the modeling in my code enough? is it possible to add more variables to the modeling of the problem, to further improve the modeling of the problem, and to do logical inference more easily when choosing the right actions:
2. You should be using functions given in the utils.py file! There should be enough functions to utilize and implement all the ideas needed to solve the exercise.
3. According to lecture, the exercise code should be based on knowledge base integration! to Utilize a more formal knowledge base to store and query logical relations between cells, enhancing inference capabilities beyond the belief matrices.
This is important, from the lecture which was mentioned in my message, the inferences should be from the current knowledge base, consider the constraints, and also enlarge the knowledge base progressively based on the observations over time!
Leveraging the PropKB or PropDefiniteKB from utils.py can significantly enhance your controller's inference capabilities. By representing observations and constraints formally within a KB, you can utilize established logical inference mechanisms to deduce the state of the environment more efficiently.
4. Improve logical inference! It can be done through: a. constraint propogation (Implement constraint propagation techniques to deduce the state of cells immediately after updating beliefs, reducing the need for extensive backtracking.)
5. The action selection should be enhanced in a way that: (and beside probability, offer an alternative approach as well maybe)
5.1 Prioritize Safe Exploration
5.2 Dynamic Goal Reassessment
Continuously reassess goals based on new inferences to adapt to the evolving knowledge of the environment. There might be a few vaults with hallows in the map! and there will be!
5.3 if it helps reducing the number of turns required to reach targets, Incorporate Orientation in Movement Decisions
Use Harry's orientation to optimize movement actions
6. Optimizing Inference Efficiency
6.1 A. Limit Backtracking Depth
Set a limit on the depth of backtracking to prevent excessive computation, especially in larger grids.
6.2 Early Pruning
Implement early pruning strategies to discard infeasible paths quickly based on current constraints.
6.3 C. Incremental Inference Updates
Instead of re-evaluating all constraints from scratch after each observation, update only the affected parts of the belief system.
6.4 Utilize Heuristics in DPLL
Incorporate heuristic-based variable ordering in your DPLL implementation to prioritize assignments that are more likely to lead to a solution, thereby reducing the search space and speeding up inference.
7. Continuous Learning and Adaptation
Implement mechanisms for the controller to learn from past actions and observations, refining its strategies over time. This adaptive approach can lead to more intelligent navigation and decision-making.